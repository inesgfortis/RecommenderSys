{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25ddcd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../movies')\n",
    "from movieLens import MovieLens\n",
    "\n",
    "# Load the movie Lens class\n",
    "ml = MovieLens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5869c5",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "819e196c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "# from RBM import RBM\n",
    "\n",
    "from surprise import accuracy\n",
    "# import heapq\n",
    "# from collections import defaultdict\n",
    "# from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50029917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the ratings dataset\n",
    "ratings = ml.ratings.copy()\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2dd1a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.0, 5.0, 3.0, 2.0, 1.0, 4.5, 3.5, 2.5, 0.5, 1.5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ratings['rating'].nunique())\n",
    "list(ratings['rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aa65764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method from the Surprise library to load the DataFrame \n",
    "# Define the Reader object to parse the dataframe\n",
    "reader = Reader(rating_scale=(ratings['rating'].min(), ratings['rating'].max()))\n",
    "\n",
    "# Load the dataframe as a ratings dataset\n",
    "ratingsDataset = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Build the full trainset\n",
    "trainSet, testSet = train_test_split(ratingsDataset, test_size=0.2, random_state=42)\n",
    "antitest = trainSet.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1d6a99",
   "metadata": {},
   "source": [
    "# PRUEBA 1: NOT OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa7cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Updated on Sun Dec 1 08:32:13 2019\n",
    "\n",
    "@author: Frank\n",
    "\n",
    "@modified: Saurabh\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "class RBM(AlgoBase):\n",
    "\n",
    "    def __init__(self, visibleDimensions, epochs=20, hiddenDimensions=50, ratingValues=10, learningRate=0.001, batchSize=100):\n",
    "        AlgoBase.__init__(self)\n",
    "        self.visibleDimensions = visibleDimensions # product of the number of movies and how many distinct rating values you have\n",
    "        self.epochs = epochs\n",
    "        self.hiddenDimensions = hiddenDimensions\n",
    "        self.ratingValues = ratingValues # unique rating values\n",
    "        self.learningRate = learningRate\n",
    "        self.batchSize = batchSize\n",
    "        \n",
    "    # in order to reconstract any users rating for any item            \n",
    "    def Train(self, X):\n",
    "\n",
    "        # Initialize weights randomly (earlier versions of thie code had this block inside MakeGraph, but that was a bug.)\n",
    "        maxWeight = -4.0 * np.sqrt(6.0 / (self.hiddenDimensions + self.visibleDimensions))\n",
    "        self.weights = tf.Variable(tf.random.uniform([self.visibleDimensions, self.hiddenDimensions], minval=-maxWeight, maxval=maxWeight), tf.float32, name=\"weights\")\n",
    "        self.hiddenBias = tf.Variable(tf.zeros([self.hiddenDimensions], tf.float32, name=\"hiddenBias\"))\n",
    "        self.visibleBias = tf.Variable(tf.zeros([self.visibleDimensions], tf.float32, name=\"visibleBias\"))\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            \n",
    "            trX = np.array(X)\n",
    "            for i in range(0, trX.shape[0], self.batchSize):\n",
    "                epochX = trX[i:i+self.batchSize]\n",
    "                self.MakeGraph(epochX)\n",
    "\n",
    "            print(\"Trained epoch \", epoch)\n",
    "\n",
    "    # get back rating predictions for a given user\n",
    "    def GetRecommendations(self, inputUser):\n",
    "        \n",
    "        feed = self.MakeHidden(inputUser)\n",
    "        rec = self.MakeVisible(feed)\n",
    "        return rec[0]       \n",
    "\n",
    "    def MakeGraph(self, inputUser):\n",
    "        \n",
    "        # Perform Gibbs Sampling for Contrastive Divergence, per the paper we assume k=1 instead of iterating over the \n",
    "        # forward pass multiple times since it seems to work just fine\n",
    "        \n",
    "        # Forward pass\n",
    "        # Sample hidden layer given visible...\n",
    "        # Get tensor of hidden probabilities\n",
    "        hProb0 = tf.nn.sigmoid(tf.matmul(inputUser, self.weights) + self.hiddenBias)\n",
    "        # Sample from all of the distributions\n",
    "        hSample = tf.nn.relu(tf.sign(hProb0 - tf.random.uniform(tf.shape(hProb0))))\n",
    "        # Stitch it together\n",
    "        forward = tf.matmul(tf.transpose(inputUser), hSample)\n",
    "        \n",
    "        # Backward pass\n",
    "        # Reconstruct visible layer given hidden layer sample\n",
    "        v = tf.matmul(hSample, tf.transpose(self.weights)) + self.visibleBias\n",
    "        \n",
    "        # Build up our mask for missing ratings\n",
    "        vMask = tf.sign(inputUser) # Make sure everything is 0 or 1\n",
    "        # User + movie + indicator of movie been rated\n",
    "        vMask3D = tf.reshape(vMask, [tf.shape(v)[0], -1, self.ratingValues]) # Reshape into arrays of individual ratings\n",
    "        vMask3D = tf.reduce_max(vMask3D, axis=[2], keepdims=True) # Use reduce_max to either give us 1 for ratings that exist, and 0 for missing ratings\n",
    "        \n",
    "        # Extract rating vectors for each individual set of 10 rating binary values\n",
    "        v = tf.reshape(v, [tf.shape(v)[0], -1, self.ratingValues])\n",
    "        vProb = tf.nn.softmax(v * vMask3D) # Apply softmax activation function\n",
    "        vProb = tf.reshape(vProb, [tf.shape(v)[0], -1]) # And shove them back into the flattened state. Reconstruction is done now.\n",
    "        # vProb = reconstructed data\n",
    "\n",
    "        # Stitch it together to define the backward pass and updated hidden biases\n",
    "        hProb1 = tf.nn.sigmoid(tf.matmul(vProb, self.weights) + self.hiddenBias)\n",
    "        backward = tf.matmul(tf.transpose(vProb), hProb1)\n",
    "    \n",
    "        # Now define what each epoch will do...\n",
    "        # Run the forward and backward passes, and update the weights\n",
    "        weightUpdate = self.weights.assign_add(self.learningRate * (forward - backward))\n",
    "        # Update hidden bias, minimizing the divergence in the hidden nodes\n",
    "        hiddenBiasUpdate = self.hiddenBias.assign_add(self.learningRate * tf.reduce_mean(hProb0 - hProb1, 0))\n",
    "        # Update the visible bias, minimizng divergence in the visible results\n",
    "        visibleBiasUpdate = self.visibleBias.assign_add(self.learningRate * tf.reduce_mean(inputUser - vProb, 0))\n",
    "\n",
    "        self.update = [weightUpdate, hiddenBiasUpdate, visibleBiasUpdate]\n",
    "        \n",
    "    def MakeHidden(self, inputUser):\n",
    "        hidden = tf.nn.sigmoid(tf.matmul(inputUser, self.weights) + self.hiddenBias)\n",
    "        self.MakeGraph(inputUser)\n",
    "        return hidden\n",
    "    \n",
    "    def MakeVisible(self, feed):\n",
    "        visible = tf.nn.sigmoid(tf.matmul(feed, tf.transpose(self.weights)) + self.visibleBias)\n",
    "        #self.MakeGraph(feed)\n",
    "        return visible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41c9f31",
   "metadata": {},
   "source": [
    "Para preparar los datos de train y test, necesitamos crear conjuntos en formato de matriz con cada fila representando a un usuario y cada celda de la fila representando la valoración de cada película, dado que esta es la entrada esperada por el algoritmo RBM.\n",
    "\n",
    "Para ello, necesitamos el número total de usuarios como números de fila y el número total de películas como número de columna\n",
    "* num_users = trainSet.n_users\n",
    "* num_movies = trainSet.n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70d49bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitData(trainset):\n",
    "    #AlgoBase.fit(self, trainset)\n",
    "\n",
    "    num_users = trainset.n_users\n",
    "    num_movies = trainset.n_items\n",
    "    \n",
    "    # 3D matrix: users, movies and ratings\n",
    "    # Ratings has size 10 given the possible rating values\n",
    "    trainingMatrix = np.zeros([num_users, num_movies, 10], dtype=np.float32)\n",
    "\n",
    "    for (uid, iid, rating) in trainset.all_ratings():\n",
    "        adjustedRating = int(float(rating)*2.0) - 1\n",
    "        trainingMatrix[int(uid), int(iid), adjustedRating] = 1\n",
    "\n",
    "    # Flatten to a 2D array, with nodes for each possible rating type on each possible item, for every user.\n",
    "    trainingMatrix = np.reshape(trainingMatrix, [trainingMatrix.shape[0], -1])\n",
    "    \n",
    "    return trainingMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "625fa382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 89280)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingMatrix = fitData(trainSet)\n",
    "trainingMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e31768e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n"
     ]
    }
   ],
   "source": [
    "#from RBM import RBM\n",
    "\n",
    "# Create an RBM with (num items * rating values) visible nodes\n",
    "model = RBM(trainingMatrix.shape[1])\n",
    "model.Train(trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "634099d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(rbm,num_users,num_movies,trainingMatrix):\n",
    "    \n",
    "    predictedRatings = np.zeros([num_users, num_movies], dtype=np.float32)\n",
    "    \n",
    "    for uiid in range(num_users):\n",
    "        if (uiid % 50 == 0):\n",
    "            print(\"Processing user \", uiid)\n",
    "        recs = rbm.GetRecommendations([trainingMatrix[uiid]])\n",
    "        recs = np.reshape(recs, [num_movies, 10])\n",
    "\n",
    "        for itemID, rec in enumerate(recs):\n",
    "            # The obvious thing would be to just take the rating with the highest score:                \n",
    "            #rating = rec.argmax()\n",
    "            # ... but this just leads to a huge multi-way tie for 5-star predictions.\n",
    "            # The paper suggests performing normalization over K values to get probabilities\n",
    "            # and take the expectation as your prediction, so we'll do that instead:\n",
    "\n",
    "            normalized = np.exp(rec)/np.sum(np.exp(rec), axis=0)\n",
    "            rating = np.average(np.arange(10), weights=normalized)\n",
    "            \n",
    "            predictedRatings[uiid, itemID] = (rating + 1) * 0.5\n",
    "\n",
    "    return predictedRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "542f7d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n"
     ]
    }
   ],
   "source": [
    "# Equivalent to model.fit\n",
    "predictedRatings = getPredictions(model,trainSet.n_users,trainSet.n_items,trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46fb06de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.773814 , 3.064343 , 2.8469872, ..., 2.7710757, 2.767178 ,\n",
       "        2.7762666],\n",
       "       [2.7737737, 3.064343 , 2.8469286, ..., 2.771031 , 2.7671473,\n",
       "        2.7762048],\n",
       "       [2.773733 , 3.0637488, 2.8468156, ..., 2.770986 , 2.7671165,\n",
       "        2.776143 ],\n",
       "       ...,\n",
       "       [2.7716875, 3.0711865, 2.8488548, ..., 2.7715204, 2.7691114,\n",
       "        2.775508 ],\n",
       "       [2.7686617, 3.058133 , 2.8350325, ..., 2.7684906, 2.7659638,\n",
       "        2.772562 ],\n",
       "       [2.771769 , 3.071522 , 2.849195 , ..., 2.7715907, 2.769186 ,\n",
       "        2.7755623]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictedRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa6080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3613aacb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd04cfb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m mae \u001b[38;5;241m=\u001b[39m accuracy\u001b[38;5;241m.\u001b[39mmae(predictions)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\accuracy.py:43\u001b[0m, in \u001b[0;36mrmse\u001b[1;34m(predictions, verbose)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrmse\u001b[39m(predictions, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute RMSE (Root Mean Squared Error).\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    .. math::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m        ValueError: When ``predictions`` is empty.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predictions:\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction list is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m     mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\n\u001b[0;32m     47\u001b[0m         [\u001b[38;5;28mfloat\u001b[39m((true_r \u001b[38;5;241m-\u001b[39m est) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m (_, _, true_r, est, _) \u001b[38;5;129;01min\u001b[39;00m predictions]\n\u001b[0;32m     48\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde63717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc376b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172c32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d1c283d",
   "metadata": {},
   "source": [
    "# Prueba 2: OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d64b27c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RBMAlgorithm import RBMAlgorithm\n",
    "RBM = RBMAlgorithm(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d53494c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n",
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n"
     ]
    }
   ],
   "source": [
    "# Fit the RBM model on the training set\n",
    "RBM.fit(trainSet)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = RBM.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab7fe63c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RBM.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef038434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ebb0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec1743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187efc7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8ab45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4d3d1a2",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24e5fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../metrics')\n",
    "from metrics import evaluationMetrics\n",
    "em = evaluationMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb35a4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test and antitest predictions\n",
    "predtest = model.test(testSet)\n",
    "predantitest = model.test(antitest)\n",
    "\n",
    "# Get top N recommended movies for each user based on estimated ratings\n",
    "top_10_RBM = em.getTopN(predantitest,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64af3b50",
   "metadata": {},
   "source": [
    "## Métricas de precisión: RMSE y MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ae52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE\n",
    "rmse = accuracy.rmse(predtest)\n",
    "\n",
    "# MAE\n",
    "mae = accuracy.mae(predtest)\n",
    "\n",
    "# rmse = accuracy.rmse(predictions)\n",
    "# mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5e195",
   "metadata": {},
   "source": [
    "## Métricas de relevancia: Precision, Recall y NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a37b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "precisions = em.getPrecision(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Precision\n",
    "mapModel = np.mean(list(precisions.values()))\n",
    "\n",
    "# Recall\n",
    "recalls = em.getRecall(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Recall\n",
    "marModel = np.mean(list(recalls.values()))\n",
    "\n",
    "# Normalized discounted cummulative gain (NDCG)\n",
    "ndcgs, mean_ndcg = em.getNDCG(predtest,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779f695b",
   "metadata": {},
   "source": [
    "## Otras métricas de interés: Coverage, User Coverage y Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5442ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage\n",
    "coverage = em.getCoverage(top_10_RBM,trainSet.n_items,trainSet.all_users())\n",
    "\n",
    "# User coverage\n",
    "user_coverage = em.getUserCoverage(top_10_RBM, trainSet.n_users,4)\n",
    "\n",
    "# Novelty\n",
    "novelty = em.getNovelty(top_10_RBM,trainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d2ceb6",
   "metadata": {},
   "source": [
    "Por último creamos un dataframe con todas las métricas de evaluación asociadas al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b67df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Model\",\"RMSE\",\"MAE\",\"MAP\",\"MAR\",\"Mean_NDCG\",\"Coverage\",\"User_Coverage\",\"Novelty\"]\n",
    "metrics_data = []\n",
    "\n",
    "# Append the results to the list of dictionaries\n",
    "metrics_data.append({\"Model\": \"RBM\", \"RMSE\": rmse, \"MAE\": mae, \"MAP\": mapModel, \"MAR\": marModel,\n",
    "                     \"Mean_NDCG\": mean_ndcg, \"Coverage\": coverage, \"User_Coverage\": user_coverage,\n",
    "                     \"Novelty\": novelty})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=cols)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5b7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57f5de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eae41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74ff1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "912e47bf",
   "metadata": {},
   "source": [
    "# Random Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c50d70",
   "metadata": {},
   "source": [
    "Vamos a evaluar también un modelo Random, en concreto \"NormalPredictor\" para poder comparar sus resultados con el resto de modelos. NormalPredictor es un algoritmo simple en Surprise que predice calificaciones aleatoriamente basado en la distribución del conjunto de entrenamiento. Supone una distribución normal de las calificaciones y genera predicciones aleatorias en función de esa distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cb303cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.random_pred.NormalPredictor at 0x207dc9e5790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import NormalPredictor\n",
    "\n",
    "# Create the model\n",
    "Random = NormalPredictor()\n",
    "Random.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdcaddfc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get test and antitest predictions\n",
    "predtest_random = Random.test(testSet)\n",
    "predantitest_random = Random.test(antitest)\n",
    "\n",
    "# Get top N recommended movies for each user based on estimated ratings\n",
    "top_10_random = em.getTopN(predantitest_random,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b9dff",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f67edd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4320\n",
      "MAE:  1.1429\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Metrics\n",
    "rmse_random = accuracy.rmse(predtest_random)\n",
    "mae_random = accuracy.mae(predtest_random)\n",
    "\n",
    "# Relevance metrics\n",
    "precisions_random = em.getPrecision(predtest_random, k=10, threshold=3.5)\n",
    "mapModel_random = np.mean(list(precisions_random.values()))\n",
    "\n",
    "recalls_random = em.getRecall(predtest_random, k=10, threshold=3.5)\n",
    "marModel_random = np.mean(list(recalls_random.values()))\n",
    "\n",
    "ndcgs_random, mean_ndcg_random = em.getNDCG(predtest_random,10)\n",
    "\n",
    "# Other metrics\n",
    "coverage_random = em.getCoverage(top_10_random,trainSet.n_items,trainSet.all_users())\n",
    "user_coverage_random = em.getUserCoverage(top_10_random, trainSet.n_users,4)\n",
    "novelty_random = em.getNovelty(top_10_random,trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d36e36fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAR</th>\n",
       "      <th>Mean_NDCG</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>User_Coverage</th>\n",
       "      <th>Novelty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>1.432009</td>\n",
       "      <td>1.142851</td>\n",
       "      <td>0.629926</td>\n",
       "      <td>0.293679</td>\n",
       "      <td>0.931162</td>\n",
       "      <td>0.029682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1846.098361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model      RMSE       MAE       MAP       MAR  Mean_NDCG  Coverage  \\\n",
       "0  random  1.432009  1.142851  0.629926  0.293679   0.931162  0.029682   \n",
       "\n",
       "   User_Coverage      Novelty  \n",
       "0            1.0  1846.098361  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"Model\",\"RMSE\",\"MAE\",\"MAP\",\"MAR\",\"Mean_NDCG\",\"Coverage\",\"User_Coverage\",\"Novelty\"]\n",
    "metrics_data = []\n",
    "\n",
    "# Append the results to the list of dictionaries\n",
    "metrics_data.append({\"Model\": \"random\", \"RMSE\": rmse_random, \"MAE\": mae_random, \"MAP\": mapModel_random, \"MAR\": marModel_random,\n",
    "                     \"Mean_NDCG\": mean_ndcg_random, \"Coverage\": coverage_random, \"User_Coverage\": user_coverage_random,\n",
    "                     \"Novelty\": novelty_random})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=cols)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6240378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results to the dataframe with the metrics of all models.\n",
    "em.addToMetricsDataframe(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
