{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c98a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../movies')\n",
    "from movieLens import MovieLens\n",
    "\n",
    "# Load the movie Lens class\n",
    "ml = MovieLens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d24f02",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95cc33ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "# from RBM import RBM\n",
    "\n",
    "from surprise import accuracy\n",
    "# import heapq\n",
    "# from collections import defaultdict\n",
    "# from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f774f513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the ratings dataset\n",
    "ratings = ml.ratings.copy()\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b659f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.0, 5.0, 3.0, 2.0, 1.0, 4.5, 3.5, 2.5, 0.5, 1.5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ratings['rating'].nunique())\n",
    "list(ratings['rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8364da89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method from the Surprise library to load the DataFrame \n",
    "# Define the Reader object to parse the dataframe\n",
    "reader = Reader(rating_scale=(ratings['rating'].min(), ratings['rating'].max()))\n",
    "\n",
    "# Load the dataframe as a ratings dataset\n",
    "ratingsDataset = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Build the full trainset\n",
    "trainSet, testSet = train_test_split(ratingsDataset, test_size=0.2, random_state=42)\n",
    "antitest = trainSet.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986d98f5",
   "metadata": {},
   "source": [
    "# PRUEBA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3557200a",
   "metadata": {},
   "source": [
    "Para preparar los datos de train y test, necesitamos crear conjuntos en formato de matriz con cada fila representando a un usuario y cada celda de la fila representando la valoración de cada película, dado que esta es la entrada esperada por el algoritmo RBM.\n",
    "\n",
    "Para ello, necesitamos el número total de usuarios como números de fila y el número total de películas como número de columna\n",
    "* num_users = trainSet.n_users\n",
    "* num_movies = trainSet.n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71494ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitData(trainset):\n",
    "    #AlgoBase.fit(self, trainset)\n",
    "\n",
    "    num_users = trainset.n_users\n",
    "    num_movies = trainset.n_items\n",
    "    \n",
    "    # 3D matrix: users, movies and ratings\n",
    "    # Ratings has size 10 given the possible rating values\n",
    "    trainingMatrix = np.zeros([num_users, num_movies, 10], dtype=np.float32)\n",
    "\n",
    "    for (uid, iid, rating) in trainset.all_ratings():\n",
    "        adjustedRating = int(float(rating)*2.0) - 1\n",
    "        trainingMatrix[int(uid), int(iid), adjustedRating] = 1\n",
    "\n",
    "    # Flatten to a 2D array, with nodes for each possible rating type on each possible item, for every user.\n",
    "    trainingMatrix = np.reshape(trainingMatrix, [trainingMatrix.shape[0], -1])\n",
    "    \n",
    "    return trainingMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2269a24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingMatrix = fitData(trainSet)\n",
    "trainingMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RBM import RBM\n",
    "\n",
    "# Create an RBM with (num items * rating values) visible nodes\n",
    "model = RBM(trainingMatrix.shape[1])\n",
    "model.train(trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7de948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(rbm,num_users,num_movies,trainingMatrix):\n",
    "    \n",
    "    predictedRatings = np.zeros([num_users, num_movies], dtype=np.float32)\n",
    "    \n",
    "    for uiid in range(num_users):\n",
    "        if (uiid % 50 == 0):\n",
    "            print(\"Processing user \", uiid)\n",
    "        recs = rbm.getRecommendations([trainingMatrix[uiid]])\n",
    "        recs = np.reshape(recs, [num_movies, 10])\n",
    "\n",
    "        for itemID, rec in enumerate(recs):\n",
    "            # The obvious thing would be to just take the rating with the highest score:                \n",
    "            #rating = rec.argmax()\n",
    "            # ... but this just leads to a huge multi-way tie for 5-star predictions.\n",
    "            # The paper suggests performing normalization over K values to get probabilities\n",
    "            # and take the expectation as your prediction, so we'll do that instead:\n",
    "\n",
    "            normalized = np.exp(rec)/np.sum(np.exp(rec), axis=0)\n",
    "            rating = np.average(np.arange(10), weights=normalized)\n",
    "            \n",
    "            predictedRatings[uiid, itemID] = (rating + 1) * 0.5\n",
    "\n",
    "    return predictedRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6afb95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = getPredictions(model,trainSet.n_users,trainSet.n_items,trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ee071b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a53ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a35e206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d85f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c538d8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c76d6d66",
   "metadata": {},
   "source": [
    "# Prueba 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae89de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RBM_v2 import RBM_v2\n",
    "\n",
    "# Create an RBM with (num items * rating values) visible nodes\n",
    "model2 = RBM_v2(trainingMatrix.shape[1])\n",
    "model2.train(trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1901519a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = getPredictions(model2,trainSet.n_users,trainSet.n_items,trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24f53e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94085cc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model2.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554ace35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "# Load the dataframe as a ratings dataset\n",
    "ratingsDataset = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "trainSet, testSet = train_test_split(ratingsDataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ed6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907840f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67775ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import accuracy\n",
    "from surprise import Prediction\n",
    "\n",
    "# Assuming `testSet` is the list of tuples\n",
    "\n",
    "# Convert the testSet tuples into Prediction objects\n",
    "prediction_objects = [Prediction(uid=t[0], iid=t[1], r_ui=t[2], est=predictions[i], details={})\n",
    "                      for i, t in enumerate(testSet)]\n",
    "\n",
    "# Calculate RMSE and MAE\n",
    "rmse = accuracy.rmse(prediction_objects)\n",
    "mae = accuracy.mae(prediction_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7bcc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b93e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4321498b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f727b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d34753b",
   "metadata": {},
   "source": [
    "# Probar si con RBM AlgotBase se pueden sacar las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RBMAlgorithm import RBMAlgorithm\n",
    "RBM = RBMAlgorithm(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84189b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "RBM.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a061e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06ce41f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11ba7770",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a8f0849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../metrics')\n",
    "from metrics import evaluationMetrics\n",
    "em = evaluationMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf07999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test and antitest predictions\n",
    "predtest = model.test(testSet)\n",
    "predantitest = model.test(antitest)\n",
    "\n",
    "# Get top N recommended movies for each user based on estimated ratings\n",
    "top_10_RBM = em.getTopN(predantitest,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b25e80",
   "metadata": {},
   "source": [
    "## Métricas de precisión: RMSE y MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE\n",
    "rmse = accuracy.rmse(predtest)\n",
    "\n",
    "# MAE\n",
    "mae = accuracy.mae(predtest)\n",
    "\n",
    "# rmse = accuracy.rmse(predictions)\n",
    "# mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100b958",
   "metadata": {},
   "source": [
    "## Métricas de relevancia: Precision, Recall y NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d9520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "precisions = em.getPrecision(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Precision\n",
    "mapModel = np.mean(list(precisions.values()))\n",
    "\n",
    "# Recall\n",
    "recalls = em.getRecall(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Recall\n",
    "marModel = np.mean(list(recalls.values()))\n",
    "\n",
    "# Normalized discounted cummulative gain (NDCG)\n",
    "ndcgs, mean_ndcg = em.getNDCG(predtest,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd34a4b",
   "metadata": {},
   "source": [
    "## Otras métricas de interés: Coverage, User Coverage y Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af20eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage\n",
    "coverage = em.getCoverage(top_10_RBM,trainSet.n_items,trainSet.all_users())\n",
    "\n",
    "# User coverage\n",
    "user_coverage = em.getUserCoverage(top_10_RBM, trainSet.n_users,4)\n",
    "\n",
    "# Novelty\n",
    "novelty = em.getNovelty(top_10_RBM,trainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa1f5e0",
   "metadata": {},
   "source": [
    "Por último creamos un dataframe con todas las métricas de evaluación asociadas al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0822a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Model\",\"RMSE\",\"MAE\",\"MAP\",\"MAR\",\"Mean_NDCG\",\"Coverage\",\"User_Coverage\",\"Novelty\"]\n",
    "metrics_data = []\n",
    "\n",
    "# Append the results to the list of dictionaries\n",
    "metrics_data.append({\"Model\": \"RBM\", \"RMSE\": rmse, \"MAE\": mae, \"MAP\": mapModel, \"MAR\": marModel,\n",
    "                     \"Mean_NDCG\": mean_ndcg, \"Coverage\": coverage, \"User_Coverage\": user_coverage,\n",
    "                     \"Novelty\": novelty})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=cols)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4816408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579340b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f81d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043356e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5825ecc6",
   "metadata": {},
   "source": [
    "# Random Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c8e95",
   "metadata": {},
   "source": [
    "Vamos a evaluar también un modelo Random, en concreto \"NormalPredictor\" para poder comparar sus resultados con el resto de modelos. NormalPredictor es un algoritmo simple en Surprise que predice calificaciones aleatoriamente basado en la distribución del conjunto de entrenamiento. Supone una distribución normal de las calificaciones y genera predicciones aleatorias en función de esa distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "878111a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.random_pred.NormalPredictor at 0x207dc9e5790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import NormalPredictor\n",
    "\n",
    "# Create the model\n",
    "Random = NormalPredictor()\n",
    "Random.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c6af53f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get test and antitest predictions\n",
    "predtest_random = Random.test(testSet)\n",
    "predantitest_random = Random.test(antitest)\n",
    "\n",
    "# Get top N recommended movies for each user based on estimated ratings\n",
    "top_10_random = em.getTopN(predantitest_random,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d226a76",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb5fef84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4320\n",
      "MAE:  1.1429\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Metrics\n",
    "rmse_random = accuracy.rmse(predtest_random)\n",
    "mae_random = accuracy.mae(predtest_random)\n",
    "\n",
    "# Relevance metrics\n",
    "precisions_random = em.getPrecision(predtest_random, k=10, threshold=3.5)\n",
    "mapModel_random = np.mean(list(precisions_random.values()))\n",
    "\n",
    "recalls_random = em.getRecall(predtest_random, k=10, threshold=3.5)\n",
    "marModel_random = np.mean(list(recalls_random.values()))\n",
    "\n",
    "ndcgs_random, mean_ndcg_random = em.getNDCG(predtest_random,10)\n",
    "\n",
    "# Other metrics\n",
    "coverage_random = em.getCoverage(top_10_random,trainSet.n_items,trainSet.all_users())\n",
    "user_coverage_random = em.getUserCoverage(top_10_random, trainSet.n_users,4)\n",
    "novelty_random = em.getNovelty(top_10_random,trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18668efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAR</th>\n",
       "      <th>Mean_NDCG</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>User_Coverage</th>\n",
       "      <th>Novelty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>1.432009</td>\n",
       "      <td>1.142851</td>\n",
       "      <td>0.629926</td>\n",
       "      <td>0.293679</td>\n",
       "      <td>0.931162</td>\n",
       "      <td>0.029682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1846.098361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model      RMSE       MAE       MAP       MAR  Mean_NDCG  Coverage  \\\n",
       "0  random  1.432009  1.142851  0.629926  0.293679   0.931162  0.029682   \n",
       "\n",
       "   User_Coverage      Novelty  \n",
       "0            1.0  1846.098361  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"Model\",\"RMSE\",\"MAE\",\"MAP\",\"MAR\",\"Mean_NDCG\",\"Coverage\",\"User_Coverage\",\"Novelty\"]\n",
    "metrics_data = []\n",
    "\n",
    "# Append the results to the list of dictionaries\n",
    "metrics_data.append({\"Model\": \"random\", \"RMSE\": rmse_random, \"MAE\": mae_random, \"MAP\": mapModel_random, \"MAR\": marModel_random,\n",
    "                     \"Mean_NDCG\": mean_ndcg_random, \"Coverage\": coverage_random, \"User_Coverage\": user_coverage_random,\n",
    "                     \"Novelty\": novelty_random})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=cols)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345368ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
