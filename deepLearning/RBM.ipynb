{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e0cb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../movies')\n",
    "from movieLens import MovieLens\n",
    "\n",
    "# Load the movie Lens class\n",
    "ml = MovieLens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597182f",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fc87971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "# from RBM import RBM\n",
    "\n",
    "from surprise import accuracy\n",
    "# import heapq\n",
    "# from collections import defaultdict\n",
    "# from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455f72df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ml.ratings\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bee5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method from the Surprise library to load the DataFrame \n",
    "# Define the Reader object to parse the dataframe\n",
    "reader = Reader(rating_scale=(ratings['rating'].min(), ratings['rating'].max()))\n",
    "\n",
    "# Load the dataframe as a ratings dataset\n",
    "ratingsDataset = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Build the full trainset\n",
    "#trainSet = ratingsDataset.build_full_trainset()\n",
    "trainSet, testSet = train_test_split(ratingsDataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7607fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8496495b",
   "metadata": {},
   "source": [
    "# PRUEBA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853b574c",
   "metadata": {},
   "source": [
    "Para preparar los datos de train y test, necesitamos crear conjuntos en formato de matriz con cada fila representando a un usuario y cada celda de la fila representando la valoración de cada película, dado que esta es la entrada esperada por el algoritmo RBM.\n",
    "\n",
    "Para ello, necesitamos el número total de usuarios como números de fila y el número total de películas como número de columna\n",
    "* num_users = trainSet.n_users\n",
    "* num_movies = trainSet.n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21ae95dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitData(trainset):\n",
    "    #AlgoBase.fit(self, trainset)\n",
    "\n",
    "    num_users = trainset.n_users\n",
    "    num_movies = trainset.n_items\n",
    "    \n",
    "    # 3D matrix: users, movies and ratings\n",
    "    # Ratings has size 10 given the possible rating values\n",
    "    trainingMatrix = np.zeros([num_users, num_movies, 10], dtype=np.float32)\n",
    "\n",
    "    for (uid, iid, rating) in trainset.all_ratings():\n",
    "        adjustedRating = int(float(rating)*2.0) - 1\n",
    "        trainingMatrix[int(uid), int(iid), adjustedRating] = 1\n",
    "\n",
    "    # Flatten to a 2D array, with nodes for each possible rating type on each possible item, for every user.\n",
    "    trainingMatrix = np.reshape(trainingMatrix, [trainingMatrix.shape[0], -1])\n",
    "    \n",
    "    return trainingMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ad20d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 89280)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingMatrix = fitData(trainSet)\n",
    "trainingMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf18c10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n"
     ]
    }
   ],
   "source": [
    "from RBM import RBM\n",
    "\n",
    "# Create an RBM with (num items * rating values) visible nodes\n",
    "model = RBM(trainingMatrix.shape[1])\n",
    "model.train(trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a97fd726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(rbm,num_users,num_movies,trainingMatrix):\n",
    "    \n",
    "    predictedRatings = np.zeros([num_users, num_movies], dtype=np.float32)\n",
    "    \n",
    "    for uiid in range(num_users):\n",
    "        if (uiid % 50 == 0):\n",
    "            print(\"Processing user \", uiid)\n",
    "        recs = rbm.getRecommendations([trainingMatrix[uiid]])\n",
    "        recs = np.reshape(recs, [num_movies, 10])\n",
    "\n",
    "        for itemID, rec in enumerate(recs):\n",
    "            # The obvious thing would be to just take the rating with the highest score:                \n",
    "            #rating = rec.argmax()\n",
    "            # ... but this just leads to a huge multi-way tie for 5-star predictions.\n",
    "            # The paper suggests performing normalization over K values to get probabilities\n",
    "            # and take the expectation as your prediction, so we'll do that instead:\n",
    "\n",
    "            normalized = np.exp(rec)/np.sum(np.exp(rec), axis=0)\n",
    "            rating = np.average(np.arange(10), weights=normalized)\n",
    "            \n",
    "            predictedRatings[uiid, itemID] = (rating + 1) * 0.5\n",
    "\n",
    "    return predictedRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a27ef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n"
     ]
    }
   ],
   "source": [
    "predictions = getPredictions(model,trainSet.n_users,trainSet.n_items,trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de2267d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.779465 , 3.0504014, 2.8211207, ..., 2.765604 , 2.7764707,\n",
       "        2.758736 ],\n",
       "       [2.7794168, 3.0504014, 2.8211167, ..., 2.76558  , 2.7764108,\n",
       "        2.7587187],\n",
       "       [2.7793686, 3.0497763, 2.8210335, ..., 2.7655556, 2.7763507,\n",
       "        2.7587013],\n",
       "       ...,\n",
       "       [2.7771592, 3.0582588, 2.8242025, ..., 2.7666385, 2.7776616,\n",
       "        2.7591581],\n",
       "       [2.7727664, 3.0462308, 2.812768 , ..., 2.7634869, 2.7739844,\n",
       "        2.7580013],\n",
       "       [2.7772813, 3.0585678, 2.8244917, ..., 2.7667131, 2.777739 ,\n",
       "        2.7591944]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4edf28e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e4ca03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7e0d423",
   "metadata": {},
   "source": [
    "# Probar si con RBM AlgotBase se pueden sacar las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2188196f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfdd7ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c7ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc10dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48bb1a7c",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60968a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../metrics')\n",
    "from metrics import evaluationMetrics\n",
    "em = evaluationMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9382ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test and antitest predictions\n",
    "predtest = model.test(testSet)\n",
    "predantitest = model.test(antitest)\n",
    "\n",
    "# Get top N recommended movies for each user based on estimated ratings\n",
    "top_10_SVD = em.getTopN(predantitest,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a824ab",
   "metadata": {},
   "source": [
    "## Métricas de precisión: RMSE y MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cafeaa78",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # RMSE\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# rmse = accuracy.rmse(predtest)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# # MAE\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# mae = accuracy.mae(predtest)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m mae \u001b[38;5;241m=\u001b[39m accuracy\u001b[38;5;241m.\u001b[39mmae(predictions)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\accuracy.py:43\u001b[0m, in \u001b[0;36mrmse\u001b[1;34m(predictions, verbose)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrmse\u001b[39m(predictions, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute RMSE (Root Mean Squared Error).\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    .. math::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m        ValueError: When ``predictions`` is empty.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predictions:\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction list is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m     mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\n\u001b[0;32m     47\u001b[0m         [\u001b[38;5;28mfloat\u001b[39m((true_r \u001b[38;5;241m-\u001b[39m est) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m (_, _, true_r, est, _) \u001b[38;5;129;01min\u001b[39;00m predictions]\n\u001b[0;32m     48\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# # RMSE\n",
    "# rmse = accuracy.rmse(predtest)\n",
    "\n",
    "# # MAE\n",
    "# mae = accuracy.mae(predtest)\n",
    "\n",
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac37cc",
   "metadata": {},
   "source": [
    "## Métricas de relevancia: Precision, Recall y NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53d4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "precisions = em.getPrecision(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Precision\n",
    "mapModel = np.mean(list(precisions.values()))\n",
    "\n",
    "# Recall\n",
    "recalls = em.getRecall(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Recall\n",
    "marModel = np.mean(list(recalls.values()))\n",
    "\n",
    "# Normalized discounted cummulative gain (NDCG)\n",
    "ndcgs, mean_ndcg = em.getNDCG(predtest,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeffd55",
   "metadata": {},
   "source": [
    "## Otras métricas de interés: Coverage, User Coverage y Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a39426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage\n",
    "coverage = em.getCoverage(top_10_SVD,trainSet.n_items,trainSet.all_users())\n",
    "\n",
    "# User coverage\n",
    "user_coverage = em.getUserCoverage(top_10_SVD, trainSet.n_users,4)\n",
    "\n",
    "# Novelty\n",
    "novelty = em.getNovelty(top_10_SVD,trainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc79b53",
   "metadata": {},
   "source": [
    "Por último creamos un dataframe con todas las métricas de evaluación asociadas al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdbd5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Model\",\"RMSE\",\"MAE\",\"MAP\",\"MAR\",\"Mean_NDCG\",\"Coverage\",\"User_Coverage\",\"Novelty\"]\n",
    "metrics_data = []\n",
    "\n",
    "# Append the results to the list of dictionaries\n",
    "metrics_data.append({\"Model\": \"item-based\", \"RMSE\": rmse, \"MAE\": mae, \"MAP\": mapModel, \"MAR\": marModel,\n",
    "                     \"Mean_NDCG\": mean_ndcg, \"Coverage\": coverage, \"User_Coverage\": user_coverage,\n",
    "                     \"Novelty\": novelty})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=cols)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718303a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd3e06e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c11fde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42d37d32",
   "metadata": {},
   "source": [
    "Vamos a evaluar también un modelo Random, en concreto \"NormalPredictor\" para poder comparar sus resultados con el resto de modelos. NormalPredictor es un algoritmo simple en Surprise que predice calificaciones aleatoriamente basado en la distribución del conjunto de entrenamiento. Supone una distribución normal de las calificaciones y genera predicciones aleatorias en función de esa distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import NormalPredictor\n",
    "\n",
    "Random = NormalPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf08597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
