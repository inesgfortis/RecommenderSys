{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c565d87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../movies')\n",
    "from movieLens import MovieLens\n",
    "\n",
    "# Load the movie Lens class\n",
    "ml = MovieLens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049af52f",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e07f9a7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "# from RBM import RBM\n",
    "\n",
    "from surprise import accuracy\n",
    "# import heapq\n",
    "# from collections import defaultdict\n",
    "# from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9eb24ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the ratings dataset\n",
    "ratings = ml.ratings.copy()\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee407d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.0, 5.0, 3.0, 2.0, 1.0, 4.5, 3.5, 2.5, 0.5, 1.5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ratings['rating'].nunique())\n",
    "list(ratings['rating'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4546e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method from the Surprise library to load the DataFrame \n",
    "# Define the Reader object to parse the dataframe\n",
    "reader = Reader(rating_scale=(ratings['rating'].min(), ratings['rating'].max()))\n",
    "\n",
    "# Load the dataframe as a ratings dataset\n",
    "ratingsDataset = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Build the full trainset\n",
    "trainSet, testSet = train_test_split(ratingsDataset, test_size=0.2, random_state=42)\n",
    "antitest = trainSet.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5c926f",
   "metadata": {},
   "source": [
    "# PRUEBA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa61da",
   "metadata": {},
   "source": [
    "Para preparar los datos de train y test, necesitamos crear conjuntos en formato de matriz con cada fila representando a un usuario y cada celda de la fila representando la valoración de cada película, dado que esta es la entrada esperada por el algoritmo RBM.\n",
    "\n",
    "Para ello, necesitamos el número total de usuarios como números de fila y el número total de películas como número de columna\n",
    "* num_users = trainSet.n_users\n",
    "* num_movies = trainSet.n_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf840234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitData(trainset):\n",
    "    #AlgoBase.fit(self, trainset)\n",
    "\n",
    "    num_users = trainset.n_users\n",
    "    num_movies = trainset.n_items\n",
    "    \n",
    "    # 3D matrix: users, movies and ratings\n",
    "    # Ratings has size 10 given the possible rating values\n",
    "    trainingMatrix = np.zeros([num_users, num_movies, 10], dtype=np.float32)\n",
    "\n",
    "    for (uid, iid, rating) in trainset.all_ratings():\n",
    "        adjustedRating = int(float(rating)*2.0) - 1\n",
    "        trainingMatrix[int(uid), int(iid), adjustedRating] = 1\n",
    "\n",
    "    # Flatten to a 2D array, with nodes for each possible rating type on each possible item, for every user.\n",
    "    trainingMatrix = np.reshape(trainingMatrix, [trainingMatrix.shape[0], -1])\n",
    "    \n",
    "    return trainingMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "790abae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 89280)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingMatrix = fitData(trainSet)\n",
    "trainingMatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5193cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n"
     ]
    }
   ],
   "source": [
    "from RBM import RBM\n",
    "\n",
    "# Create an RBM with (num items * rating values) visible nodes\n",
    "model = RBM(trainingMatrix.shape[1])\n",
    "model.train(trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc4c0420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(rbm,num_users,num_movies,trainingMatrix):\n",
    "    \n",
    "    predictedRatings = np.zeros([num_users, num_movies], dtype=np.float32)\n",
    "    \n",
    "    for uiid in range(num_users):\n",
    "        if (uiid % 50 == 0):\n",
    "            print(\"Processing user \", uiid)\n",
    "        recs = rbm.getRecommendations([trainingMatrix[uiid]])\n",
    "        recs = np.reshape(recs, [num_movies, 10])\n",
    "\n",
    "        for itemID, rec in enumerate(recs):\n",
    "            # The obvious thing would be to just take the rating with the highest score:                \n",
    "            #rating = rec.argmax()\n",
    "            # ... but this just leads to a huge multi-way tie for 5-star predictions.\n",
    "            # The paper suggests performing normalization over K values to get probabilities\n",
    "            # and take the expectation as your prediction, so we'll do that instead:\n",
    "\n",
    "            normalized = np.exp(rec)/np.sum(np.exp(rec), axis=0)\n",
    "            rating = np.average(np.arange(10), weights=normalized)\n",
    "            \n",
    "            predictedRatings[uiid, itemID] = (rating + 1) * 0.5\n",
    "\n",
    "    return predictedRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "621de137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n"
     ]
    }
   ],
   "source": [
    "predictions = getPredictions(model,trainSet.n_users,trainSet.n_items,trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5117672d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.773814 , 3.064343 , 2.8469872, ..., 2.7710757, 2.767178 ,\n",
       "        2.7762666],\n",
       "       [2.7737737, 3.064343 , 2.8469286, ..., 2.771031 , 2.7671473,\n",
       "        2.7762048],\n",
       "       [2.773733 , 3.0637488, 2.8468156, ..., 2.770986 , 2.7671165,\n",
       "        2.776143 ],\n",
       "       ...,\n",
       "       [2.7716875, 3.0711865, 2.8488548, ..., 2.7715204, 2.7691114,\n",
       "        2.775508 ],\n",
       "       [2.7686617, 3.058133 , 2.8350325, ..., 2.7684906, 2.7659638,\n",
       "        2.772562 ],\n",
       "       [2.771769 , 3.071522 , 2.849195 , ..., 2.7715907, 2.769186 ,\n",
       "        2.7755623]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "640b1b88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m mae \u001b[38;5;241m=\u001b[39m accuracy\u001b[38;5;241m.\u001b[39mmae(predictions)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\accuracy.py:43\u001b[0m, in \u001b[0;36mrmse\u001b[1;34m(predictions, verbose)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrmse\u001b[39m(predictions, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute RMSE (Root Mean Squared Error).\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    .. math::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m        ValueError: When ``predictions`` is empty.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predictions:\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction list is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m     mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\n\u001b[0;32m     47\u001b[0m         [\u001b[38;5;28mfloat\u001b[39m((true_r \u001b[38;5;241m-\u001b[39m est) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m (_, _, true_r, est, _) \u001b[38;5;129;01min\u001b[39;00m predictions]\n\u001b[0;32m     48\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347920d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5be330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab9f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "156cd0d3",
   "metadata": {},
   "source": [
    "# Prueba 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4897748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained epoch  0\n",
      "Trained epoch  1\n",
      "Trained epoch  2\n",
      "Trained epoch  3\n",
      "Trained epoch  4\n",
      "Trained epoch  5\n",
      "Trained epoch  6\n",
      "Trained epoch  7\n",
      "Trained epoch  8\n",
      "Trained epoch  9\n",
      "Trained epoch  10\n",
      "Trained epoch  11\n",
      "Trained epoch  12\n",
      "Trained epoch  13\n",
      "Trained epoch  14\n",
      "Trained epoch  15\n",
      "Trained epoch  16\n",
      "Trained epoch  17\n",
      "Trained epoch  18\n",
      "Trained epoch  19\n"
     ]
    }
   ],
   "source": [
    "from RBM_v2 import RBM_v2\n",
    "\n",
    "# Create an RBM with (num items * rating values) visible nodes\n",
    "model2 = RBM_v2(trainingMatrix.shape[1])\n",
    "model2.train(trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5a8d94f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user  0\n",
      "Processing user  50\n",
      "Processing user  100\n",
      "Processing user  150\n",
      "Processing user  200\n",
      "Processing user  250\n",
      "Processing user  300\n",
      "Processing user  350\n",
      "Processing user  400\n",
      "Processing user  450\n",
      "Processing user  500\n",
      "Processing user  550\n",
      "Processing user  600\n"
     ]
    }
   ],
   "source": [
    "predictions = getPredictions(model2,trainSet.n_users,trainSet.n_items,trainingMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0260bcb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7759185, 3.0417857, 2.8223495, ..., 2.7892137, 2.7807577,\n",
       "        2.754152 ],\n",
       "       [2.7758682, 3.0417857, 2.8223426, ..., 2.78913  , 2.7806926,\n",
       "        2.75415  ],\n",
       "       [2.7758176, 3.041201 , 2.822266 , ..., 2.789046 , 2.7806275,\n",
       "        2.7541478],\n",
       "       ...,\n",
       "       [2.77362  , 3.0498745, 2.8254151, ..., 2.7888005, 2.7819004,\n",
       "        2.7549882],\n",
       "       [2.7701852, 3.0389378, 2.8138025, ..., 2.7836561, 2.7772217,\n",
       "        2.7534988],\n",
       "       [2.7736878, 3.050157 , 2.825701 , ..., 2.7889109, 2.7819993,\n",
       "        2.755025 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7c9fe36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RBM_v2' object has no attribute 'trainset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestSet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:160\u001b[0m, in \u001b[0;36mAlgoBase.test\u001b[1;34m(self, testset, verbose)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03min the given testset.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    that contains all the estimated ratings.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# The ratings are translated back to their original scale.\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(uid, iid, r_ui_trans, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r_ui_trans) \u001b[38;5;129;01min\u001b[39;00m testset\n\u001b[0;32m    163\u001b[0m ]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:161\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03min the given testset.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    that contains all the estimated ratings.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# The ratings are translated back to their original scale.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_ui_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r_ui_trans) \u001b[38;5;129;01min\u001b[39;00m testset\n\u001b[0;32m    163\u001b[0m ]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:92\u001b[0m, in \u001b[0;36mAlgoBase.predict\u001b[1;34m(self, uid, iid, r_ui, clip, verbose)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Convert raw ids to inner ids\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m     iuid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241m.\u001b[39mto_inner_uid(uid)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     iuid \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUKN__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(uid)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RBM_v2' object has no attribute 'trainset'"
     ]
    }
   ],
   "source": [
    "model2.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8eb40e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rmse \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m mae \u001b[38;5;241m=\u001b[39m accuracy\u001b[38;5;241m.\u001b[39mmae(predictions)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\accuracy.py:43\u001b[0m, in \u001b[0;36mrmse\u001b[1;34m(predictions, verbose)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrmse\u001b[39m(predictions, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124;03m\"\"\"Compute RMSE (Root Mean Squared Error).\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m    .. math::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m        ValueError: When ``predictions`` is empty.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predictions:\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction list is empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m     mse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\n\u001b[0;32m     47\u001b[0m         [\u001b[38;5;28mfloat\u001b[39m((true_r \u001b[38;5;241m-\u001b[39m est) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m (_, _, true_r, est, _) \u001b[38;5;129;01min\u001b[39;00m predictions]\n\u001b[0;32m     48\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "rmse = accuracy.rmse(predictions)\n",
    "mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b1f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5df43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b46a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd1a241",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae223b1e",
   "metadata": {},
   "source": [
    "# Probar si con RBM AlgotBase se pueden sacar las métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d48f3fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RBMAlgorithm import RBMAlgorithm\n",
    "RBM = RBMAlgorithm(epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae70c8ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RBMAlgorithm' object has no attribute 'trainset'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mRBM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestSet\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:160\u001b[0m, in \u001b[0;36mAlgoBase.test\u001b[1;34m(self, testset, verbose)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03min the given testset.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    that contains all the estimated ratings.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# The ratings are translated back to their original scale.\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(uid, iid, r_ui_trans, verbose\u001b[38;5;241m=\u001b[39mverbose)\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r_ui_trans) \u001b[38;5;129;01min\u001b[39;00m testset\n\u001b[0;32m    163\u001b[0m ]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:161\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m\"\"\"Test the algorithm on given testset, i.e. estimate all the ratings\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03min the given testset.\u001b[39;00m\n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03m    that contains all the estimated ratings.\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# The ratings are translated back to their original scale.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m predictions \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_ui_trans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (uid, iid, r_ui_trans) \u001b[38;5;129;01min\u001b[39;00m testset\n\u001b[0;32m    163\u001b[0m ]\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\surprise\\prediction_algorithms\\algo_base.py:92\u001b[0m, in \u001b[0;36mAlgoBase.predict\u001b[1;34m(self, uid, iid, r_ui, clip, verbose)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# Convert raw ids to inner ids\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m     iuid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241m.\u001b[39mto_inner_uid(uid)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     iuid \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUKN__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(uid)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'RBMAlgorithm' object has no attribute 'trainset'"
     ]
    }
   ],
   "source": [
    "RBM.test(testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595096e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8d0b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bdc9fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c11e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed66197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aad63eb8",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d656bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../metrics')\n",
    "from metrics import evaluationMetrics\n",
    "em = evaluationMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bcc036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test and antitest predictions\n",
    "predtest = model.test(testSet)\n",
    "predantitest = model.test(antitest)\n",
    "\n",
    "# Get top N recommended movies for each user based on estimated ratings\n",
    "top_10_RBM = em.getTopN(predantitest,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4259726",
   "metadata": {},
   "source": [
    "## Métricas de precisión: RMSE y MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RMSE\n",
    "rmse = accuracy.rmse(predtest)\n",
    "\n",
    "# MAE\n",
    "mae = accuracy.mae(predtest)\n",
    "\n",
    "# rmse = accuracy.rmse(predictions)\n",
    "# mae = accuracy.mae(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6accb",
   "metadata": {},
   "source": [
    "## Métricas de relevancia: Precision, Recall y NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f7d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "precisions = em.getPrecision(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Precision\n",
    "mapModel = np.mean(list(precisions.values()))\n",
    "\n",
    "# Recall\n",
    "recalls = em.getRecall(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Recall\n",
    "marModel = np.mean(list(recalls.values()))\n",
    "\n",
    "# Normalized discounted cummulative gain (NDCG)\n",
    "ndcgs, mean_ndcg = em.getNDCG(predtest,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd258cd9",
   "metadata": {},
   "source": [
    "## Otras métricas de interés: Coverage, User Coverage y Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e080e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage\n",
    "coverage = em.getCoverage(top_10_RBM,trainSet.n_items,trainSet.all_users())\n",
    "\n",
    "# User coverage\n",
    "user_coverage = em.getUserCoverage(top_10_RBM, trainSet.n_users,4)\n",
    "\n",
    "# Novelty\n",
    "novelty = em.getNovelty(top_10_RBM,trainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb70b3",
   "metadata": {},
   "source": [
    "Por último creamos un dataframe con todas las métricas de evaluación asociadas al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a3dc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"Model\",\"RMSE\",\"MAE\",\"MAP\",\"MAR\",\"Mean_NDCG\",\"Coverage\",\"User_Coverage\",\"Novelty\"]\n",
    "metrics_data = []\n",
    "\n",
    "# Append the results to the list of dictionaries\n",
    "metrics_data.append({\"Model\": \"RBM\", \"RMSE\": rmse, \"MAE\": mae, \"MAP\": mapModel, \"MAR\": marModel,\n",
    "                     \"Mean_NDCG\": mean_ndcg, \"Coverage\": coverage, \"User_Coverage\": user_coverage,\n",
    "                     \"Novelty\": novelty})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=cols)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9a08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485517f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c2303c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109c89f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73224d55",
   "metadata": {},
   "source": [
    "# Random Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdbf884",
   "metadata": {},
   "source": [
    "Vamos a evaluar también un modelo Random, en concreto \"NormalPredictor\" para poder comparar sus resultados con el resto de modelos. NormalPredictor es un algoritmo simple en Surprise que predice calificaciones aleatoriamente basado en la distribución del conjunto de entrenamiento. Supone una distribución normal de las calificaciones y genera predicciones aleatorias en función de esa distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1bd8c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.random_pred.NormalPredictor at 0x207dc9e5790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import NormalPredictor\n",
    "\n",
    "# Create the model\n",
    "Random = NormalPredictor()\n",
    "Random.fit(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa7dd502",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get test and antitest predictions\n",
    "predtest_random = Random.test(testSet)\n",
    "predantitest_random = Random.test(antitest)\n",
    "\n",
    "# Get top N recommended movies for each user based on estimated ratings\n",
    "top_10_random = em.getTopN(predantitest_random,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ffb331",
   "metadata": {},
   "source": [
    "## Compute metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "854ee888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.4320\n",
      "MAE:  1.1429\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Metrics\n",
    "rmse_random = accuracy.rmse(predtest_random)\n",
    "mae_random = accuracy.mae(predtest_random)\n",
    "\n",
    "# Relevance metrics\n",
    "precisions_random = em.getPrecision(predtest_random, k=10, threshold=3.5)\n",
    "mapModel_random = np.mean(list(precisions_random.values()))\n",
    "\n",
    "recalls_random = em.getRecall(predtest_random, k=10, threshold=3.5)\n",
    "marModel_random = np.mean(list(recalls_random.values()))\n",
    "\n",
    "ndcgs_random, mean_ndcg_random = em.getNDCG(predtest_random,10)\n",
    "\n",
    "# Other metrics\n",
    "coverage_random = em.getCoverage(top_10_random,trainSet.n_items,trainSet.all_users())\n",
    "user_coverage_random = em.getUserCoverage(top_10_random, trainSet.n_users,4)\n",
    "novelty_random = em.getNovelty(top_10_random,trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d785636c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAR</th>\n",
       "      <th>Mean_NDCG</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>User_Coverage</th>\n",
       "      <th>Novelty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random</td>\n",
       "      <td>1.432009</td>\n",
       "      <td>1.142851</td>\n",
       "      <td>0.629926</td>\n",
       "      <td>0.293679</td>\n",
       "      <td>0.931162</td>\n",
       "      <td>0.029682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1846.098361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model      RMSE       MAE       MAP       MAR  Mean_NDCG  Coverage  \\\n",
       "0  random  1.432009  1.142851  0.629926  0.293679   0.931162  0.029682   \n",
       "\n",
       "   User_Coverage      Novelty  \n",
       "0            1.0  1846.098361  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"Model\",\"RMSE\",\"MAE\",\"MAP\",\"MAR\",\"Mean_NDCG\",\"Coverage\",\"User_Coverage\",\"Novelty\"]\n",
    "metrics_data = []\n",
    "\n",
    "# Append the results to the list of dictionaries\n",
    "metrics_data.append({\"Model\": \"random\", \"RMSE\": rmse_random, \"MAE\": mae_random, \"MAP\": mapModel_random, \"MAR\": marModel_random,\n",
    "                     \"Mean_NDCG\": mean_ndcg_random, \"Coverage\": coverage_random, \"User_Coverage\": user_coverage_random,\n",
    "                     \"Novelty\": novelty_random})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=cols)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dbdd2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results to the dataframe with the metrics of all models.\n",
    "em.addToMetricsDataframe(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
