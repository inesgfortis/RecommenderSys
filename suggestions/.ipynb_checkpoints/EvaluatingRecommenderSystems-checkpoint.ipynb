{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4c87f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../movies')\n",
    "from movieLens import MovieLens\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from surprise import Dataset, Reader, KNNBasic, SVD, KNNWithMeans, KNNWithZScore\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5580a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = MovieLens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5025b26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ml.ratings\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "95d3c46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96100</th>\n",
       "      <td>603</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>963178147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96101</th>\n",
       "      <td>603</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>963177624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96102</th>\n",
       "      <td>603</td>\n",
       "      <td>16</td>\n",
       "      <td>4.0</td>\n",
       "      <td>963179585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96103</th>\n",
       "      <td>603</td>\n",
       "      <td>17</td>\n",
       "      <td>3.0</td>\n",
       "      <td>954482210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96104</th>\n",
       "      <td>603</td>\n",
       "      <td>21</td>\n",
       "      <td>5.0</td>\n",
       "      <td>963177624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97038</th>\n",
       "      <td>603</td>\n",
       "      <td>4815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1002403253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97039</th>\n",
       "      <td>603</td>\n",
       "      <td>4823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1002403269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97040</th>\n",
       "      <td>603</td>\n",
       "      <td>4855</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1002403400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97041</th>\n",
       "      <td>603</td>\n",
       "      <td>5060</td>\n",
       "      <td>3.0</td>\n",
       "      <td>953926877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97042</th>\n",
       "      <td>603</td>\n",
       "      <td>6184</td>\n",
       "      <td>5.0</td>\n",
       "      <td>963176419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating   timestamp\n",
       "96100     603        1     4.0   963178147\n",
       "96101     603        6     4.0   963177624\n",
       "96102     603       16     4.0   963179585\n",
       "96103     603       17     3.0   954482210\n",
       "96104     603       21     5.0   963177624\n",
       "...       ...      ...     ...         ...\n",
       "97038     603     4815     1.0  1002403253\n",
       "97039     603     4823     1.0  1002403269\n",
       "97040     603     4855     4.0  1002403400\n",
       "97041     603     5060     3.0   953926877\n",
       "97042     603     6184     5.0   963176419\n",
       "\n",
       "[943 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[ratings[\"userId\"] == 603]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffbf87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Reader object to parse the dataframe\n",
    "reader = Reader(rating_scale=(ratings['rating'].min(), ratings['rating'].max()))\n",
    "\n",
    "# Load the dataframe as a ratings dataset\n",
    "ratingsDataset = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1962427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago este split para sacar métricas después\n",
    "trainset, testset = train_test_split(ratingsDataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24970e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Voy a usar la misma configuración y el mismo modelo que has usado en tu caso\n",
    "sim_options = {'name': 'pearson',  # alternative: cosine\n",
    "               'user_based': True, # compute  similarities between users\n",
    "               'min_support':5     # minimum number of common items between users\n",
    "               }\n",
    "modelA = KNNWithMeans(sim_options=sim_options)\n",
    "modelA.fit(trainset)\n",
    "simsMatrix = modelA.compute_similarities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b7581ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1381bd96670>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelB = SVD()\n",
    "modelB.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d099b",
   "metadata": {},
   "source": [
    "# Métricas\n",
    "\n",
    "Vamos a poner a comparar los dos modelos, en primer lugar, las métricas de predicción más simples y más básicas que serían el RMSE y el MAE, en estos casos, lo que se busca es encontrar una medida de distancia entre las predicciones de los ratings que realizan los modelos y el rating real que los usuarios han valorado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "212dca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predtestA = modelA.test(testset)\n",
    "predtestB = modelB.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fcbfdfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "antitest = trainset.build_anti_testset()\n",
    "predantitestA = modelA.test(antitest)\n",
    "predantitestB = modelB.test(antitest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c149fb",
   "metadata": {},
   "source": [
    "## Métricas de precisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "070163f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9030\n",
      "El RMSE del modelo A es de: 0.9029931528241073\n",
      "RMSE: 0.8779\n",
      "El RMSE del modelo B es de: 0.8779007754100654\n"
     ]
    }
   ],
   "source": [
    "print(\"El RMSE del modelo A es de: {}\".format(accuracy.rmse(predtestA)))\n",
    "print(\"El RMSE del modelo B es de: {}\".format(accuracy.rmse(predtestB)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b5772d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.6864\n",
      "El MAE del modelo A es de: 0.6864474629038703\n",
      "MAE:  0.6745\n",
      "El MAE del modelo B es de: 0.6744839722371379\n"
     ]
    }
   ],
   "source": [
    "print(\"El MAE del modelo A es de: {}\".format(accuracy.mae(predtestA)))\n",
    "print(\"El MAE del modelo B es de: {}\".format(accuracy.mae(predtestB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc5d69",
   "metadata": {},
   "source": [
    "En este caso el modelo B (SVD) esta haciendo predicciones ligeramente más precisas, aunque no mucho mejor, por lo tanto, no podemos dar ningún recomendador mejor que otro. \n",
    "\n",
    "Hay que tener en cuenta que estas métricas de precisión no son muy muy importantes ya que, ¿para qué quiero predecir estupendamente una película que he valorado con un 1 si no la debería recomendar nunca? O al contrario, ¿qué más me da predecir una película valorada con un 5 con un 4.8 o un 4.3 si la decisión al final va a ser la misma? Obviamente es importante tener una buena precisión de las predicciones de los ratings pero al final lo importante es que las recomendaciones que realicemos aporten valor.\n",
    "\n",
    "Para esto lo primero es encontrar las top N recomendaciones del conjunto de test que estamos probando y comprobar cuales de estas son realmente relevantes. En este caso trabajaremos con el top 10, pero puede ser interesante tomar diferentes valores de N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80df07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetTopN(predictions, n=10, minimumRating=4.0):\n",
    "    topN = defaultdict(list)\n",
    "\n",
    "    for userID, movieID, actualRating, estimatedRating, _ in predictions:\n",
    "        if (estimatedRating >= minimumRating):\n",
    "            topN[int(userID)].append((int(movieID), estimatedRating))\n",
    "\n",
    "    for userID, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[int(userID)] = ratings[:n]\n",
    "\n",
    "    return topN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "00728670",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10modelA = GetTopN(predantitestA,minimumRating = 3.5)\n",
    "top10modelB = GetTopN(predantitestB,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e315c36f",
   "metadata": {},
   "source": [
    "## Métricas de relevancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258dfa04",
   "metadata": {},
   "source": [
    "Las dos métricas que considero de más valor para evaluar un recomendador serían Precision@K y Recall@K. Para definirlos hay que tener en cuenta lo siguiente:\n",
    "\n",
    "* Se necesita establecer un threshold mínimo para indicar un corte entre algo que se considera positivo y algo que no lo es.\n",
    "* Diremos que una valoración de un usuario es **Relevante** si la ha puntuado igual o por encima de un threshold dado.\n",
    "* Una recomendación será **Valorada** dentro del top K de recomendaciones si la predicción del modelo es mayor o igual a un threshold dado.\n",
    "\n",
    "Con estas condiciones definimos la Precision@K y el Recall@K:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Precision@K} = \\dfrac{\\# (\\text{Relevantes en K}\\cap\\text{Valoradas en K})}{\\#\\text{Valoradas en K}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Recall@K} = \\dfrac{\\# (\\text{Relevantes en K}\\cap\\text{Valoradas en K})}{\\#\\text{Relevantes}}\n",
    "\\end{equation}\n",
    "\n",
    "\"\\#\" Denota el número de elementos de ese conjunto. Veamoslo con un ejemplo:\n",
    "\n",
    "Tenemos la siguiente lista de valoraciones y predicciones para un usuario:\n",
    "\n",
    "| Usuario | Película   | Rating | Predicción |\n",
    "|---------|------------|--------|------------|\n",
    "| 1       | Película A | 4.5    | 4.2        |\n",
    "| 1       | Película B | 3      | 3.6        |\n",
    "| 1       | Película C | 2.5    | 2.1        |\n",
    "| 1       | Película D | 4      | 3.9        |\n",
    "| 1       | Película E | 1.5    | 1.8        |\n",
    "| 1       | Película F | 2      | 2.4        |\n",
    "| 1       | Película G | 3.5    | 3.7        |\n",
    "| 1       | Película H | 4.5    | 4.1        |\n",
    "| 1       | Película I | 2      | 2.6        |\n",
    "| 1       | Película J | 3.5    | 3.3        |\n",
    "\n",
    "Vamos a establecer un threshold de 4 para este caso. Entonces tendríamos que las valoraciones de las películas A, D y H serían relevantes por superar este threshold.\n",
    "\n",
    "Supongamos que queremos calcular la precision@3 (K = 3). Las recomendaciones según el modelo serían las películas A, H y D por ser los que más predicción tienen. De estas recomendaciones, consideraremos valoradas todas aquellas que superan el threshold anterior. Por lo tanto, en este caso, Solo las películas A y H serían valoradas ya que D tiene una predicción de 3.9. Ambas películas valoradas son al mismo tiempo relevantes ya que el usuario las puntuó por encima de 4. Con todo esto, la precisión sería:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Precision@3} = \\dfrac{2}{2} = 1\n",
    "\\end{equation}\n",
    "\n",
    "Esto se interpreta de la siguiente manera: de las recomendaciones que considero valoradas todas son relevantes para el usuario. No hay ningún falso positivo.\n",
    "\n",
    "Por otra parte, el recall@3 sería: \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Recall@3} = \\dfrac{2}{3}\n",
    "\\end{equation}\n",
    "\n",
    "En este caso tenemos un falso negativo, ya que para el modelo la película D no supera el umbral y por tanto no es valorada pero el usuario la puntuó por igual o por encima de 4 por lo tanto si es relevante.\n",
    "\n",
    "Aquí dejo la implementación de Surprise para calcular en cada usuario su precisión y recall en K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "db4d8af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        # When n_rec_k is 0, Precision is undefined. We here set it to 0.\n",
    "\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6579e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "precisionsA, recallsA = precision_recall_at_k(predtestA, k=10, threshold=3.5)\n",
    "precisionsB, recallsB = precision_recall_at_k(predtestB, k=10, threshold=3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2313e7",
   "metadata": {},
   "source": [
    "Estos objetos devuelven un valor de precision y recall para cada usuario del conjunto de test en cada modelo. Para obtener un dato agregado se definen las siguientes métricas.\n",
    "\n",
    "* **Mean Average Precision at K (MAP@K)**: Media de todas las precisiones obtenidas en el paso anterior.\n",
    "* **Mean Average Recall at K (MAR@K)**: Media de todos los recalls obtenidos en el paso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0872260b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MAP@10 del modelo A (KNN) es de 0.7299186833203226\n",
      "El MAP@10 del modelo B (SVD) es de 0.7466595107988552\n"
     ]
    }
   ],
   "source": [
    "print(f\"El MAP@10 del modelo A (KNN) es de {np.mean(list(precisionsA.values()))}\")\n",
    "print(f\"El MAP@10 del modelo B (SVD) es de {np.mean(list(precisionsB.values()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c9440dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MAR@10 del modelo A (KNN) es de 0.524003569900473\n",
      "El MAR@10 del modelo B (SVD) es de 0.5124586823133307\n"
     ]
    }
   ],
   "source": [
    "print(f\"El MAR@10 del modelo A (KNN) es de {np.mean(list(recallsA.values()))}\")\n",
    "print(f\"El MAR@10 del modelo B (SVD) es de {np.mean(list(recallsB.values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fdb168",
   "metadata": {},
   "source": [
    "El modelo A tiene algo menos de precisión pero mejor recall, esto significa que cuando el modelo afirma que una recomendación es buena tiene menos probabilidad de acierto que el modelo B, sin embargo el modelo A ha detectado un poco más de valoraciones altas por parte de un usuario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ea2241",
   "metadata": {},
   "source": [
    "Otro factor importante a la hora de realizar un recomendador es la posición de la recomendación, siempre debemos intentar dejar las mejores recomendaciones de los usuarios en las primeras posiciones a la hora de mostrarlas. Consideramos las siguientes recomendaciones ordenadas por su predicción, es decir, este sería el orden que le mostraríamos al usuario en caso de recomendarle 5 películas.\n",
    "\n",
    "| Usuario | Película   | Rating | Predicción |\n",
    "|---------|------------|--------|------------|\n",
    "| 1       | Película A | 4.5    | 4.6        |\n",
    "| 1       | Película B | 4      | 4.4        |\n",
    "| 1       | Película C | 5      | 4.2        |\n",
    "| 1       | Película D | 3.5    | 4.1        |\n",
    "| 1       | Película E | 5      | 4          |\n",
    "\n",
    "Definimos la ganancia acumulada de las recomendaciones como la suma de los ratings reales de las recomendaciones anteriores, es decir:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Cumulative Gain@k (CG@k)} = \\sum_{i = 1}^{k} \\text{Rating Real}_{k} = 4 + 4.5 + 5 + 3.5 + 5 = 22\n",
    "\\end{equation}\n",
    "\n",
    "Esta métrica todavía no tiene en cuenta el orden, una manera de tener en cuenta el orden es dividir cada rating por un factor. Este factor va a penalizar más fuerte conforme avanza k. Así se define el Discounted Cumulative Gain.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Discounted Cumulative Gain@k (DCG@k)} = \\sum_{i = 1}^{k} \\dfrac{\\text{Rating Real}_{k}}{\\log_{2}(i+1)} = \\dfrac{4.5}{\\log_{2}(2)} + \\dfrac{4}{\\log_{2}(3)} + \\dfrac{5}{\\log_{2}(4)} + \\dfrac{3.5}{\\log_{2}(5)} + \\dfrac{5}{\\log_{2}(6)} = 12.96\n",
    "\\end{equation}\n",
    "\n",
    "Aquí me interesa que el modelo ponga las mejores puntuaciones reales al principio, por esa razón voy dividiendo por una cantidad cada vez mayor. Como esta métrica no está acotada, conviene encontrar una manera de reducir este número a un intervalo acotado. Para ello se considera la mejor ordenación posible de los ratings anteriores.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{ideal Discounted Cumulative Gain@k (iDCG@k)} = \\sum_{i = 1}^{k} \\dfrac{\\text{Rating Real ordenado}_{k}}{\\log_{2}(i+1)} = \\dfrac{5}{\\log_{2}(2)} + \\dfrac{5}{\\log_{2}(3)} + \\dfrac{4.5}{\\log_{2}(4)} + \\dfrac{4}{\\log_{2}(5)} + \\dfrac{3.5}{\\log_{2}(6)} = 13.48\n",
    "\\end{equation}\n",
    "\n",
    "De esta manera puedo saber \"como de lejos\" me he quedado de la mejor ordenación posible. El cociente de ambas me devuelve un valor entre 0 y 1 que indica lo \"bien\" que mi modelo ha ordenado las recomendaciones\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Normalized Discounted Cumulative Gain@k (NDCG@k)} = \\dfrac{\\text{DCG}}{\\text{iDCG}} = \\dfrac{12.96}{13.48} = 0.96\n",
    "\\end{equation}\n",
    "\n",
    "Existen maneras más agresivas de penalizar los errores de posiciones en las fórmulas anteriores. También hay que tener en cuenta que se penaliza más grande es K.\n",
    "\n",
    "Para poder implementar esta métrica tenemos que adaptar el formato de la salida de las predicciones del modelo a un formato que permita trabajar las fórmulas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8ccbcd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_predictions_to_dataframe(predictions):\n",
    "    data = []\n",
    "    for uid, iid, true_r, est_r, _ in predictions:\n",
    "        data.append([uid,iid,true_r,est_r])\n",
    "        \n",
    "    df = pd.DataFrame(data, columns = [\"user_id\", \"movie_id\",\"rating\",\"prediction\"])\n",
    "    df.sort_values([\"user_id\",\"prediction\"],inplace = True, ascending = [True,False])\n",
    "    \n",
    "    return df\n",
    "\n",
    "dftestA = from_predictions_to_dataframe(predtestA)\n",
    "dftestB = from_predictions_to_dataframe(predtestB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f50c67",
   "metadata": {},
   "source": [
    "Ahora ya podemos implementar la funcion que calcula el NDCG. Como esto se calcula para cada usuario, un método de agregación podría ser establecer la media de todos ellos aunque también se puede estudiar la distribución por usuario con algún gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "64a8e685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_at_k(df,k):\n",
    "    grouped = df.groupby('user_id')\n",
    "    ndcgs = []\n",
    "    for _, group in grouped:\n",
    "        group = group.head(k)\n",
    "        group.reset_index(inplace = True, drop = True)\n",
    "        dcg = (group['rating'] / np.log2(group.index + 2)).sum()\n",
    "        ideal = group.sort_values(by='rating', ascending=False)\n",
    "        ideal.reset_index(inplace = True, drop = True)\n",
    "        idcg = (ideal['rating'] / np.log2(ideal.index + 2)).sum()\n",
    "        ndcgs.append(dcg / idcg)\n",
    "    return ndcgs, np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2b0a3bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcgsA ,mean_ndcgA = ndcg_at_k(dftestA,10)\n",
    "ndcgsB ,mean_ndcgB = ndcg_at_k(dftestB,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c2deaf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de promedio del NDCG del modelo A (KNN) es de: 0.9510456458372629\n",
      "El valor de promedio del NDCG del modelo B (SVD) es de: 0.9553076478975605\n"
     ]
    }
   ],
   "source": [
    "print(f\"El valor promedio del NDCG del modelo A (KNN) es de: {mean_ndcgA}\")\n",
    "print(f\"El valor promedio del NDCG del modelo B (SVD) es de: {mean_ndcgB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390de2fc",
   "metadata": {},
   "source": [
    "En este caso vemos que los dos modelos ordenan sus recomendaciones de una manera muy parecida. Hay que tener en cuenta que esta métrica no mide la calidad de las recomendaciones, ese valor te lo dan otras métricas que ya hemos visto antes. Una vez establecidas las recomendaciones, está métrica devuelve su capacidad de ordenación siendo 1 el mayor valor posible.\n",
    "\n",
    "Otro aspecto a tener en cuenta es que al ser escalas de 0 a 5 y ser recomendaciones relativamente buenas, los valores se quedan muy cercanos a 1, en caso de usar por ejemplo una escala de acierto-error, es decir, $\\{0,1\\}$, notaríamos más la diferencia en las ordenaciones.\n",
    "\n",
    "En las métricas de precisión, recall y NDCG se podrían establecer gráficos de distribución (por ejemplo, un histograma o un boxplot) utilizando todos los datos por usuario. De esta manera podremos visualizar aspectos como cuantos usuarios se salen fuera de la media, la dispersión que pueda haber en el total de usuarios o algún otro aspecto reseñable de los usuarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394244e8",
   "metadata": {},
   "source": [
    "## Otras métricas de interés\n",
    "\n",
    "El último punto de métricas que tienen interés están más relacionadas con la _variedad_ en las recomendaciones. También es importante tenerlas en cuenta a la hora de evaluar como de bueno es un recomendador. La primera de ellas que vamos a ver es la **cobertura**. La **cobertura** (coverage) mide el porcentaje de elementos distintos del catálogo que ha devuelto el modelo como recomendación al menos una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "8df867e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(topNrec,total_items,users):\n",
    "    rec_items = []\n",
    "    \n",
    "    for user in users:\n",
    "        rec_items += [pred[0] for pred in topNrec[user]]\n",
    "    num_rec_items = len(set(rec_items))\n",
    "    \n",
    "    return num_rec_items/total_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "981df400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cobertura del modelo A (KNN) es de: 0.05432347670250896\n",
      "La cobertura del modelo B (SVD) es de: 0.03797043010752688\n"
     ]
    }
   ],
   "source": [
    "coverageA = coverage(top10modelA,trainset.n_items,trainset.all_users())\n",
    "coverageB = coverage(top10modelB,trainset.n_items,trainset.all_users())\n",
    "\n",
    "print(f\"La cobertura del modelo A (KNN) es de: {coverageA}\")\n",
    "print(f\"La cobertura del modelo B (SVD) es de: {coverageB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c48960",
   "metadata": {},
   "source": [
    "Aquí vemos como las recomendaciones son poco variadas en ambos casos un 5% en el caso del KNN y algo menos de un 4% para el SVD. En 600 usuarios, solo se han recomendado, a lo más, unas 400 y pico de películas diferentes. Es muy poco teniendo en cuenta que el catálogo dispone de 8000 películas.\n",
    "\n",
    "Una variante de la cobertura, es la **cobertura por usuario** (UserCoverage). Este valor indica el porcentaje de usuarios que han recibido, al menos, una recomendación donde el modelo entiende que es buena, es decir, una recomendación con una puntuación superior a un threshold dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "7b36b993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def UserCoverage(topNPredicted, numUsers, ratingThreshold=0):\n",
    "    hits = 0\n",
    "    for userID in topNPredicted.keys():\n",
    "        hit = False\n",
    "        for movieID, predictedRating in topNPredicted[userID]:\n",
    "            if (predictedRating >= ratingThreshold):\n",
    "                hit = True\n",
    "                break\n",
    "        if (hit):\n",
    "            hits += 1\n",
    "\n",
    "    return hits / numUsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a98fb790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cobertura por usuario del modelo A (KNN) es de: 0.9967213114754099\n",
      "La cobertura por usuario del modelo B (SVD) es de: 0.9147540983606557\n"
     ]
    }
   ],
   "source": [
    "usercoverageA = UserCoverage(top10modelA, trainset.n_users,4)\n",
    "usercoverageB = UserCoverage(top10modelB, trainset.n_users,4)\n",
    "\n",
    "print(f\"La cobertura por usuario del modelo A (KNN) es de: {usercoverageA}\")\n",
    "print(f\"La cobertura por usuario del modelo B (SVD) es de: {usercoverageB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e85c8",
   "metadata": {},
   "source": [
    "Aquí vemos como el KNN encuentra en casi todos sus usuarios al menos una recomendación por encima de 4 en su predicción, mientras que el SVD solo lo hace en el 90% de los usuarios. Existe por tanto un 10% de usuarios en el modelo SVD donde no se tiene certeza de tener al menos una recomendación con puntuación alta.\n",
    "\n",
    "Por último vamos a definir una última métrica que mide la popularidad de las recomendaciones. Esta métrica es conocida como **Novelty**. Para ello se debe establecer el concepto de popularidad dentro del conjunto de películas. Un enfoque podría ser las veces que la película ha sido calificada o también calificada por encima de un valor determinado. Vamos a construir primero esta popularidad para las películas, en este caso, por simplicidad, nos vamos a basar en el número de puntuaciones recibidas en cada película como medida de como popularidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f0c8f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = trainset.all_ratings()\n",
    "trainrank = pd.DataFrame(columns=['userid', 'movieid', 'rating'])\n",
    "i = 0\n",
    "for (uid, iid, rating) in iterator:\n",
    "    trainrank.loc[i] = [uid, iid, rating]\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "70f574d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainrank[\"userid\"] = trainrank[\"userid\"].astype(int)\n",
    "trainrank[\"movieid\"] = trainrank[\"movieid\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "0f111aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>movieid</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>398</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1348</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid  movieid  rating\n",
       "0       0        0     4.5\n",
       "1       0      398     3.0\n",
       "2       0      572     4.0\n",
       "3       0      501     2.5\n",
       "4       0     1348     3.5"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainrank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "95072f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscamos el conteo de interacciones que ha tenido una pelicula\n",
    "interacciones = trainrank[\"movieid\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4420b270",
   "metadata": {},
   "source": [
    "Por último, asignamos el 1 a la película más visitada del catálogo, el 2 a la segunda y asi sucesivamente. (Este es el enfoque del curso de udemy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "05812729",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pop = dict(zip(interacciones.index, range(1,len(interacciones)+1)))\n",
    "\n",
    "# Otra manera de definir un ranking sería escalando el número de interacciones con un \n",
    "# minmaxscaler y se le daría un 1 a la película más popular y 0 a la que menos. De esta manera el valor de \n",
    "# Novelty quedaría acotado entre 0 y 1 entendiendo que más cerca de 1 implica recomendaciones más populares.\n",
    "\n",
    "#interacciones = (interacciones - interacciones.min())/(interacciones.max() - interacciones.min())\n",
    "#dict_pop = interacciones.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd9542",
   "metadata": {},
   "source": [
    "Definimos **Novelty** como el valor promedio del ranking de las recomendaciones ofrecidas a un usuario, es decir:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Novelty} = \\dfrac{\\sum_{u \\in U} \\sum_{i \\in R_u} Rank(i)}{\\sum_{u \\in U} |R_u|}\n",
    "\\end{equation}\n",
    "\n",
    "Donde:\n",
    "\n",
    "* $U$ es el conjunto de usuarios a los que se le ha realizado al menos una recomendación\n",
    "* $R_u$ es el conjunto de recomendaciones al usuario u\n",
    "* $|R_u|$ es el número total de recomendaciones realizadas al usuario u\n",
    "* $Rank(i)$ es el ranking de la película i, va desde 1 hasta el total de películas del conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c5cc2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Novelty(topNPredicted,trainset, rankings):\n",
    "    n = 0\n",
    "    total = 0\n",
    "    for userID in topNPredicted.keys():\n",
    "        for rating in topNPredicted[userID]:\n",
    "            movieID = rating[0]\n",
    "            rank = rankings[trainset.to_inner_iid(movieID)]\n",
    "            total += rank\n",
    "            n += 1\n",
    "    return total / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "c4e3cd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de Novelty del modelo A (KNN) es de: 4231.016581842062\n",
      "El valor de Novelty del modelo B (SVD) es de: 405.5473842553903\n"
     ]
    }
   ],
   "source": [
    "noveltyA = Novelty(top10modelA,trainset, dict_pop)\n",
    "noveltyB = Novelty(top10modelB,trainset, dict_pop)\n",
    "\n",
    "print(f\"El valor de Novelty del modelo A (KNN) es de: {noveltyA}\")\n",
    "print(f\"El valor de Novelty del modelo B (SVD) es de: {noveltyB}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a77329a",
   "metadata": {},
   "source": [
    "Aquí vemos que el modelo SVD suele recomendar películas mucho más populares su ranking promedio se encuentra en torno a la película 400 más popular (de unas 8000 posibles) mientras que el modelo KNN incluye recomendaciones de películas que han sido mucho menos puntuadas entre los usuarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bdfe03",
   "metadata": {},
   "source": [
    "# Conclusiones "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30219889",
   "metadata": {},
   "source": [
    "En base a todo esto, ¿qué recomendador dirías que es mejor según estas métricas y todo lo que hemos evaluado antes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19575bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f2c6702",
   "metadata": {},
   "source": [
    "# Otras opciones y referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cc5443",
   "metadata": {},
   "source": [
    "Tanto en el curso como en los libros y en otros documentos podemos encontrar muchas más métricas que pueden ser interesantes (*HitRate*, *CumulativeHitRate*, *RatingHitRate*, *AverageReciprocalHitRank*, *Diversity*, *Serendipia*, *Curvas ROC*...) yo he intentado cubrir tantas como creo que nos pueden servir para evaluar correctamente un recomendador. Si ves que hay algún concepto que se nos escape a medida que vamos desarrollando podemos incluir alguna métrica más a estas.\n",
    "\n",
    "Al mismo tiempo te dejo por aquí algunas referencias de lo que he utilizado para montar todo este notebook. Espero que te sirvan.\n",
    "\n",
    "* Recommender Systems (Charu C. Arggarwal)\n",
    "* https://medium.com/fnplus/evaluating-recommender-systems-with-python-code-ae0c370c90be\n",
    "* https://towardsdatascience.com/ranking-evaluation-metrics-for-recommender-systems-263d0a66ef54#:~:text=In%20recommender%20settings%2C%20the%20hit,included%20in%20the%20recommendation%20list.\n",
    "* https://github.com/jvntra/Movie_Recommendation_System_Framework\n",
    "* https://github.com/NicolasHug/Surprise/blob/master/examples/precision_recall_at_k.py\n",
    "* Código del curso de udemy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
