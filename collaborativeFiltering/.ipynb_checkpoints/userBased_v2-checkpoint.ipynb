{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed4ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../movies')\n",
    "from movieLens import MovieLens\n",
    "\n",
    "# Load the movie Lens class\n",
    "ml = MovieLens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95605bd",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee9269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset, Reader, KNNWithMeans\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463c55e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = ml.ratings\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d131b0b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Method from the Surprise library to load the DataFrame \n",
    "# Define the Reader object to parse the dataframe\n",
    "reader = Reader(rating_scale=(ratings['rating'].min(), ratings['rating'].max()))\n",
    "\n",
    "# Load the dataframe as a ratings dataset\n",
    "ratingsDataset = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Build the full trainset\n",
    "#trainSet = ratingsDataset.build_full_trainset()\n",
    "trainSet, testSet = train_test_split(ratingsDataset, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db58e6",
   "metadata": {},
   "source": [
    "## User item rating matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c085ac",
   "metadata": {},
   "source": [
    "Matriz en la que encontramos los ratings por usuario para cada una de las películas existentes. Una columna para los usuarios y una fila en la que se encuentran todas las películas disponibles. El valor de la celda corresponde con el rating otorgado por el usuario a la película"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121ea9d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity function\n",
    "sim_options = {'name': 'pearson',  # alternative: cosine\n",
    "               'user_based': True, # compute  similarities between users\n",
    "               'min_support':5     # minimum number of common items between users\n",
    "               }\n",
    "\n",
    "model = KNNWithMeans(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27a353",
   "metadata": {},
   "source": [
    "La métrica establecida corresponde con el coeficiente de pearson, dado funciona mejor que la métrica \"cosine similarity\" en terminos de similitud entre usuarios porque tiene en cuenta como \"puntúan\" los usuarios las películas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daca2d75",
   "metadata": {},
   "source": [
    "## User similarity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f592cac2",
   "metadata": {},
   "source": [
    "Comparamos usuarios para detectar aquellos con perfil similar al de referencia (al que queremos recomendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0da813eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 610)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSet.all_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71720439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ratings[ratings['userId']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a819224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference user = user to recommend to\n",
    "referenceUser = 1 \n",
    "\n",
    "# Set the number of desired similar users\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d10a3",
   "metadata": {},
   "source": [
    "## Look up similar users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f3390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(referenceUser,k,trainSet,threshold=None):\n",
    "    \n",
    "    # Get top N similar users to our reference user\n",
    "    referenceUserInnerID = trainSet.to_inner_uid(referenceUser)\n",
    "    \n",
    "    if threshold is None:\n",
    "        similarityRow = simsMatrix[referenceUserInnerID]\n",
    "        similarUsers = []\n",
    "        for innerID, score in enumerate(similarityRow):\n",
    "            if (innerID != referenceUserInnerID):\n",
    "                similarUsers.append((innerID, score))\n",
    "                \n",
    "    # Alternative. Select users up to a similarity threshold\n",
    "    else:\n",
    "        similarUsers = [(innerID, score) for (innerID, score) in enumerate(simsMatrix[referenceUserInnerID])\n",
    "                if innerID != referenceUserInnerID and score > threshold]\n",
    "    \n",
    "    #print(len(similarUsers))\n",
    "   \n",
    "    # Get top N\n",
    "    # Sort the elements in decreasing order by score and select top N\n",
    "    kNeighbors = heapq.nlargest(k, similarUsers, key=lambda t: t[1])\n",
    "    \n",
    "    return kNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14ed14f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(322, 0.9359709753334591),\n",
       " (127, 0.8816752506454788),\n",
       " (402, 0.8507462787278184),\n",
       " (352, 0.8416254115301732),\n",
       " (424, 0.8236319355254453),\n",
       " (507, 0.7905694150420948),\n",
       " (74, 0.7821029549487571),\n",
       " (561, 0.7467286566323438),\n",
       " (512, 0.737043474095502),\n",
       " (589, 0.7288689868556625)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1. No threshold\n",
    "kNeighbors = getNeighbors(referenceUser,10,trainSet)\n",
    "kNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21bf0b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(322, 0.9359709753334591),\n",
       " (127, 0.8816752506454788),\n",
       " (402, 0.8507462787278184),\n",
       " (352, 0.8416254115301732),\n",
       " (424, 0.8236319355254453)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2. Set a threshold value\n",
    "kNeighbors2 = getNeighbors(referenceUser,10,trainSet,0.8)\n",
    "kNeighbors2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3a16e",
   "metadata": {},
   "source": [
    "Vemos que el número de perfiles similares disminuye como consecuencia de estabecer un coeficiente de similitud mínimo (threshold = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf34f074",
   "metadata": {},
   "source": [
    "## Candidate generation and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244bec4c",
   "metadata": {},
   "source": [
    "Selecionamos las películas que podríamos recomendar en primera instancia "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96f64e",
   "metadata": {},
   "source": [
    "### First approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36af0506",
   "metadata": {},
   "source": [
    "Normalizamos los ratings y multiplicamos por el coeficiente de semejanza entre el usuario elegido y el de referencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e52037ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the stuff they rated, and add up ratings for each item, weighted by user similarity\n",
    "candidates = defaultdict(float)\n",
    "for similarUser in kNeighbors:\n",
    "    innerID = similarUser[0]\n",
    "    userSimilarityScore = similarUser[1]\n",
    "    theirRatings = trainSet.ur[innerID]\n",
    "    for rating in theirRatings:\n",
    "        candidates[rating[0]] += (rating[1] / 5.0) * userSimilarityScore\n",
    "        \n",
    "# Sort the candidates by score\n",
    "candidates = sorted(candidates.items(), key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885251b8",
   "metadata": {},
   "source": [
    "### Second approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d03cd746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the stuff they rated, and add up ratings for each item, weighted by user similarity\n",
    "candidates2 = defaultdict(float)\n",
    "similaritySum = sum([similarity[1] for similarity in kNeighbors])\n",
    "for similarUser in kNeighbors:\n",
    "    innerID = similarUser[0]\n",
    "    userSimilarityScore = similarUser[1] / similaritySum\n",
    "    theirRatings = trainSet.ur[innerID]\n",
    "    for itemID, rating in theirRatings:\n",
    "        candidates2[itemID] += round(userSimilarityScore * rating,2)\n",
    "\n",
    "# Sort the candidates by score\n",
    "candidates2 = sorted(candidates2.items(), key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c208c61",
   "metadata": {},
   "source": [
    "El primer enfoque es más sencillo pero puede estar sesgado hacia películas muy valorados, ya que sólo tiene en cuenta la suma de las valoraciones. El segundo enfoque tiene en cuenta tanto la valoración como la puntuación de similitud, lo que puede hacerlo más preciso y menos sesgado. Sin embargo, requiere más cálculos y su aplicación puede resultar más compleja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e97e79",
   "metadata": {},
   "source": [
    "## Candidate filtering and recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3332c6",
   "metadata": {},
   "source": [
    "Filtramos aquellas recomendaciones con un score pequeño y que ya haya visto el usuario. Para ello utilizamos un set porque únicamente nos interesa saber los items que el reference user ya ha visto, plus es un objeto eficiente para datasets largos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "309421e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterRec(referenceUser,trainSet, candidates):\n",
    "    \n",
    "    # Get top N similar users to our reference user\n",
    "    referenceUserInnerID = trainSet.to_inner_uid(referenceUser)\n",
    "    \n",
    "    # Build a set of movies the user has already seen\n",
    "    watched = set(trainSet.ur[referenceUserInnerID])\n",
    "    \n",
    "    # Initialize a list to store the recommendations\n",
    "    recommendations = []\n",
    "\n",
    "    # Get top-rated items from similar users:\n",
    "    pos = 0\n",
    "    for itemID, ratingSum in candidates:\n",
    "        if not itemID in watched:\n",
    "            movieID = trainSet.to_raw_iid(itemID)\n",
    "            recommendation = ml.getMovieName(int(movieID)), ratingSum\n",
    "            recommendations.append(recommendation)\n",
    "            pos += 1\n",
    "            if (pos >= 10):\n",
    "                break\n",
    "\n",
    "    rec_movies = [rec[0] for rec in recommendations]\n",
    "    return rec_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059ff0c",
   "metadata": {},
   "source": [
    "ratingSum represents the total similarity of the reference user to all other users who rated that item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6448b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Star Wars: Episode VI - Return of the Jedi',\n",
       " 'Usual Suspects, The',\n",
       " 'Seven (a.k.a. Se7en)',\n",
       " 'Forrest Gump',\n",
       " 'Star Wars: Episode IV - A New Hope',\n",
       " 'Matrix, The',\n",
       " 'Twelve Monkeys (a.k.a. 12 Monkeys)',\n",
       " 'Lord of the Rings: The Two Towers, The',\n",
       " 'Firm, The',\n",
       " 'Green Mile, The']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results for the first approach\n",
    "rec_movies = filterRec(referenceUser,trainSet, candidates)\n",
    "rec_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07a2f0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Usual Suspects, The',\n",
       " 'Star Wars: Episode VI - Return of the Jedi',\n",
       " 'Seven (a.k.a. Se7en)',\n",
       " 'Forrest Gump',\n",
       " 'Star Wars: Episode IV - A New Hope',\n",
       " 'Matrix, The',\n",
       " 'Twelve Monkeys (a.k.a. 12 Monkeys)',\n",
       " 'Lord of the Rings: The Two Towers, The',\n",
       " 'Firm, The',\n",
       " 'Green Mile, The']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results for the second approach\n",
    "rec_movies2 = filterRec(referenceUser,trainSet, candidates2)\n",
    "rec_movies2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f722e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(rec_movies == rec_movies2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6ceb33",
   "metadata": {},
   "source": [
    "Vemos que ambos métodos obtienen recomendaciones muy similares. No obstante, difieren en la última película sugerida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83821aac",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b969d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluationMetrics\n",
    "em = evaluationMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dce55a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test predictions\n",
    "predtest = model.test(testSet)\n",
    "\n",
    "# Antitest\n",
    "antitest = trainSet.build_anti_testset()\n",
    "predantitest = model.test(antitest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24d0e06",
   "metadata": {},
   "source": [
    "Un antitest set es una técnica utilizada en la evaluación de sistemas de recomendación que tiene como objetivo evitar la selección aleatoria de pares usuario-ítem que puedan sesgar los resultados de la evaluación.\n",
    "\n",
    "En lugar de seleccionar al azar los usuarios y los elementos para el conjunto de prueba, un antitest set se selecciona de manera más cuidadosa y sistemática para garantizar que no se incluyan datos que podrían conducir a una evaluación engañosa. Por ejemplo, en un antitest set, se pueden excluir aquellos usuarios y elementos que tienen pocas calificaciones o que tienen una correlación atípica con otros usuarios o elementos en el conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999f1144",
   "metadata": {},
   "source": [
    "## Métricas de precisión "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ebcf8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9030\n",
      "El RMSE del modelo es de: 0.9029931528241073\n",
      "MAE:  0.6864\n",
      "El MAE del modelo es de: 0.6864474629038703\n"
     ]
    }
   ],
   "source": [
    "# Compute evaluation metrics: RMSE and MAE\n",
    "print(\"El RMSE del modelo es de: {}\".format(accuracy.rmse(predtest)))\n",
    "print(\"El MAE del modelo es de: {}\".format(accuracy.mae(predtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c331372e",
   "metadata": {},
   "source": [
    "La primera métrica que tenemos es que el recomendador estima con un error de 0.90 puntos de RMSE y 0.68 puntos de media. Intuitivamente esto quiere decir que, si se recomienda una película a un usuario con una puntuación estimada de 3.5, es razonable esperar que la puntuación que el usuario asigne a la película esté en el rango de 2.6 a 4.4, ya que la estimación del recomendador puede estar fuera en una cantidad de aproximadamente 0.90 puntos en cualquier dirección. Sin embargo, esta es una estimación aproximada y el error puede variar dependiendo del usuario y la película en cuestión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0bb065",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que estas métricas de precisión no son muy muy importantes ya que, ¿para qué quiero predecir estupendamente una película que he valorado con un 1 si no la debería recomendar nunca? O al contrario, ¿qué más me da predecir una película valorada con un 5 con un 4.8 o un 4.3 si la decisión al final va a ser la misma? Obviamente es importante tener una buena precisión de las predicciones de los ratings pero al final lo importante es que las recomendaciones que realicemos aporten valor.\n",
    "\n",
    "Para esto lo primero es encontrar las top N recomendaciones del conjunto de test que estamos probando y comprobar cuales de estas son realmente relevantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "917efd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top N recommended movies for each user based on estimated ratings\n",
    "top_10 = em.getTopN(predantitest,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc0a48",
   "metadata": {},
   "source": [
    "## Métricas de relevancia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2c739",
   "metadata": {},
   "source": [
    "### Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fb5cd",
   "metadata": {},
   "source": [
    "Se ha considerdo que las dos métricas que aportan más valor a la hora de evaluar un recomendador son Precision y Recall dado un número de recomendaciones k. Para definirlos hay que tener en cuenta lo siguiente:\n",
    "\n",
    "* Se necesita establecer un threshold mínimo para indicar un corte entre algo que se considera positivo y algo que no lo es.\n",
    "* Diremos que una valoración de un usuario es **Relevante** si la ha puntuado igual o por encima de un threshold dado.\n",
    "* Una recomendación será **Valorada** dentro del top K de recomendaciones si la predicción del modelo es mayor o igual a un threshold dado.\n",
    "\n",
    "Con estas condiciones definimos la Precision@K y el Recall@K:\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Precision@K} = \\dfrac{\\# (\\text{Relevantes en K}\\cap\\text{Valoradas en K})}{\\#\\text{Valoradas en K}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Recall@K} = \\dfrac{\\# (\\text{Relevantes en K}\\cap\\text{Valoradas en K})}{\\#\\text{Relevantes}}\n",
    "\\end{equation}\n",
    "\n",
    "Donde \"\\#\" Denota el número de elementos de ese conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd4aea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision and recall\n",
    "precisions = em.getPrecision(predtest, k=10, threshold=3.5)\n",
    "recalls = em.getRecall(predtest, k=10, threshold=3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf9848",
   "metadata": {},
   "source": [
    "Estos objetos devuelven un valor de precision y recall para cada usuario del conjunto de test en cada modelo. Para obtener un dato agregado se definen las siguientes métricas.\n",
    "\n",
    "* **Mean Average Precision at K (MAP@K)**: Media de todas las precisiones obtenidas en el paso anterior.\n",
    "* **Mean Average Recall at K (MAR@K)**: Media de todos los recalls obtenidos en el paso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f9cd36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El MAP@10 del modelo es de 0.7299186833203226\n",
      "El MAR@10 del modelo es de 0.4667214959398828\n"
     ]
    }
   ],
   "source": [
    "print(f\"El MAP@10 del modelo es de {np.mean(list(precisions.values()))}\")\n",
    "print(f\"El MAR@10 del modelo es de {np.mean(list(recalls.values()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e31ae63",
   "metadata": {},
   "source": [
    "### Normalized Discounted Cummulative Gain (NDCG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeafabe",
   "metadata": {},
   "source": [
    "Otro factor importante a la hora de realizar un recomendador es la posición de la recomendación, siempre debemos intentar dejar las mejores recomendaciones de los usuarios en las primeras posiciones a la hora de mostrarlas.\n",
    "\n",
    "Definimos la ganancia acumulada de las recomendaciones como la suma de los ratings reales de las recomendaciones anteriores, es decir:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Cumulative Gain@k (CG@k)} = \\sum_{i = 1}^{k} \\text{Rating Real}_{k} = 4 + 4.5 + 5 + 3.5 + 5 = 22\n",
    "\\end{equation}\n",
    "\n",
    "Esta métrica todavía no tiene en cuenta el orden, una manera de tener en cuenta el orden es dividir cada rating por un factor. Este factor va a penalizar más fuerte conforme avanza k. Así se define el Discounted Cumulative Gain.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Discounted Cumulative Gain@k (DCG@k)} = \\sum_{i = 1}^{k} \\dfrac{\\text{Rating Real}_{k}}{\\log_{2}(i+1)} = \\dfrac{4.5}{\\log_{2}(2)} + \\dfrac{4}{\\log_{2}(3)} + \\dfrac{5}{\\log_{2}(4)} + \\dfrac{3.5}{\\log_{2}(5)} + \\dfrac{5}{\\log_{2}(6)} = 12.96\n",
    "\\end{equation}\n",
    "\n",
    "Aquí me interesa que el modelo ponga las mejores puntuaciones reales al principio, por esa razón voy dividiendo por una cantidad cada vez mayor. Como esta métrica no está acotada, conviene encontrar una manera de reducir este número a un intervalo acotado. Para ello se considera la mejor ordenación posible de los ratings anteriores.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{ideal Discounted Cumulative Gain@k (iDCG@k)} = \\sum_{i = 1}^{k} \\dfrac{\\text{Rating Real ordenado}_{k}}{\\log_{2}(i+1)} = \\dfrac{5}{\\log_{2}(2)} + \\dfrac{5}{\\log_{2}(3)} + \\dfrac{4.5}{\\log_{2}(4)} + \\dfrac{4}{\\log_{2}(5)} + \\dfrac{3.5}{\\log_{2}(6)} = 13.48\n",
    "\\end{equation}\n",
    "\n",
    "De esta manera puedo saber \"como de lejos\" me he quedado de la mejor ordenación posible. El cociente de ambas me devuelve un valor entre 0 y 1 que indica lo \"bien\" que mi modelo ha ordenado las recomendaciones\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Normalized Discounted Cumulative Gain@k (NDCG@k)} = \\dfrac{\\text{DCG}}{\\text{iDCG}} = \\dfrac{12.96}{13.48} = 0.96\n",
    "\\end{equation}\n",
    "\n",
    "Existen maneras más agresivas de penalizar los errores de posiciones en las fórmulas anteriores. También hay que tener en cuenta que se penaliza más grande es K.\n",
    "\n",
    "Para poder implementar esta métrica tenemos que adaptar el formato de la salida de las predicciones del modelo a un formato que permita trabajar las fórmulas anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bb93fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor promedio del NDCG del modelo es de: 0.9510456458372629\n"
     ]
    }
   ],
   "source": [
    "# Compute normalized discounted cummulative gain (NDCG)\n",
    "ndcgs, mean_ndcg = em.getNDCG(predtest,10)\n",
    "\n",
    "print(f\"El valor promedio del NDCG del modelo es de: {mean_ndcg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e74c45",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que esta métrica no mide la calidad de las recomendaciones, ese valor a partir de las métricas anteriores. Una vez establecidas las recomendaciones, está métrica devuelve su capacidad de ordenación siendo 1 el mayor valor posible.\n",
    "\n",
    "Otro aspecto a tener en cuenta es que al ser escalas de 0 a 5 y ser recomendaciones relativamente buenas, los valores se quedan muy cercanos a 1, en caso de usar por ejemplo una escala de acierto-error, es decir, $\\{0,1\\}$, la diferencia es más notable al ordenar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a759f",
   "metadata": {},
   "source": [
    "## Otras métricas de interés\n",
    "\n",
    "El último punto de métricas que tienen interés están más relacionadas con la _variedad_ en las recomendaciones. También es importante tenerlas en cuenta a la hora de evaluar como de bueno es un recomendador. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fabe71",
   "metadata": {},
   "source": [
    "### Coverage\n",
    "La primera de ellas que vamos a ver es la **cobertura**. La **cobertura** (coverage) mide el porcentaje de elementos distintos del catálogo que ha devuelto el modelo como recomendación al menos una vez."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46e50157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cobertura del modelo es de: 0.05432347670250896\n"
     ]
    }
   ],
   "source": [
    "# Compute coverage\n",
    "coverage = em.getCoverage(top_10,trainSet.n_items,trainSet.all_users())\n",
    "print(f\"La cobertura del modelo es de: {coverage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee912203",
   "metadata": {},
   "source": [
    "Aquí vemos como las recomendaciones son poco variadas, en torno a un 5%. En 600 usuarios, solo se han recomendado, a lo más, unas 400 y pico de películas diferentes. Es muy poco teniendo en cuenta que el catálogo dispone de 8000 películas.\n",
    "\n",
    "Una variante de la cobertura, es la **cobertura por usuario** (UserCoverage). Este valor indica el porcentaje de usuarios que han recibido, al menos, una recomendación donde el modelo entiende que es buena, es decir, una recomendación con una puntuación superior a un threshold dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8ef3e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cobertura por usuario del modelo es de: 0.9967213114754099\n"
     ]
    }
   ],
   "source": [
    "# Compute user coverage\n",
    "user_coverage = em.getUserCoverage(top_10, trainSet.n_users,4)\n",
    "print(f\"La cobertura por usuario del modelo es de: {user_coverage}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b061350",
   "metadata": {},
   "source": [
    "Aquí vemos como el KNN encuentra en casi todos sus usuarios al menos una recomendación por encima de 4 en su predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755c7032",
   "metadata": {},
   "source": [
    "### Novelty\n",
    "Por último vamos a definir una última métrica que mide la popularidad de las recomendaciones. Esta métrica es conocida como **Novelty**. Para ello se debe establecer el concepto de popularidad dentro del conjunto de películas. En este caso se define la popularidad de las películas en función del número de valoraciones recibidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e43c9d",
   "metadata": {},
   "source": [
    "Definimos **Novelty** como el valor promedio del ranking de las recomendaciones ofrecidas a un usuario, es decir:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Novelty} = \\dfrac{\\sum_{u \\in U} \\sum_{i \\in R_u} Rank(i)}{\\sum_{u \\in U} |R_u|}\n",
    "\\end{equation}\n",
    "\n",
    "Donde:\n",
    "\n",
    "* $U$ es el conjunto de usuarios a los que se le ha realizado al menos una recomendación\n",
    "* $R_u$ es el conjunto de recomendaciones al usuario u\n",
    "* $|R_u|$ es el número total de recomendaciones realizadas al usuario u\n",
    "* $Rank(i)$ es el ranking de la película i, va desde 1 hasta el total de películas del conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34489ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de Novelty del modelo es de: 4231.016581842062\n"
     ]
    }
   ],
   "source": [
    "# Compute novelty\n",
    "novelty = em.getNovelty(top_10,trainSet)\n",
    "\n",
    "print(f\"El valor de Novelty del modelo es de: {novelty}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f855194",
   "metadata": {},
   "source": [
    "El modelo KNN incluye recomendaciones de películas que han sido pocas veces puntuadas entre los usuarios dado que su ranking promedio se encuentra en torno a la película 4231 más popular (de 8000 posibles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
