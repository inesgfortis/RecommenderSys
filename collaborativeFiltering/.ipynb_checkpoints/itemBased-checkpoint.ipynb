{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ed4ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../movies')\n",
    "from movieLens import MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c56398",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = MovieLens()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95605bd",
   "metadata": {},
   "source": [
    "# Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eee9269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, KNNWithMeans, accuracy\n",
    "from surprise.model_selection import train_test_split, GridSearchCV\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d131b0b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the ratings dataset\n",
    "ratings = ml.ratings.copy()\n",
    "\n",
    "# Method from the Surprise library to load the DataFrame \n",
    "# Define the Reader object to parse the dataframe\n",
    "reader = Reader(rating_scale=(ratings['rating'].min(), ratings['rating'].max()))\n",
    "\n",
    "# Load the dataframe as a ratings dataset\n",
    "ratingsDataset = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Build the full trainset\n",
    "trainSet, testSet = train_test_split(ratingsDataset, test_size=0.2, random_state=42)\n",
    "antitest = trainSet.build_anti_testset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db58e6",
   "metadata": {},
   "source": [
    "## Item user rating matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c085ac",
   "metadata": {},
   "source": [
    "Matriz en la que encontramos los ratings por película para cada uno de los usuarios existentes. Una columna para las películas y una fila en la que se encuentran todos los usuarios disponibles. El valor de la celda corresponde con el rating otorgado a cada una de las películas por el usuario correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121ea9d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# Cosine similarity function\n",
    "sim_options = {'name': 'cosine',   # alternative: pearson\n",
    "               'user_based': False, # compute  similarities between films\n",
    "               'min_support':5      # minimum number of common items between users\n",
    "               }\n",
    "\n",
    "model = KNNWithMeans(sim_options=sim_options)\n",
    "model.fit(trainSet)\n",
    "simsMatrix = model.compute_similarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9d10a3",
   "metadata": {},
   "source": [
    "## Look up similar items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d691fd",
   "metadata": {},
   "source": [
    "Buscamos las k películas que el usuario de referencia haya valorado mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f3390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighbors(referenceUser,k,trainSet):\n",
    "     \n",
    "    referenceUserInnerID = trainSet.to_inner_uid(referenceUser) \n",
    "\n",
    "    # Get top N items rated\n",
    "    # Sort the elements in decreasing order by score and select top N\n",
    "    referenceUserRatings = trainSet.ur[referenceUserInnerID]\n",
    "    #print(referenceUserRatings)\n",
    "    kNeighbors = heapq.nlargest(k, referenceUserRatings, key=lambda t: t[1])\n",
    "    \n",
    "    return kNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a819224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference user = user to recommend to\n",
    "referenceUser = 1 \n",
    "\n",
    "# Set the number of desired similar users\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14ed14f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(587, 5.0),\n",
       " (18, 5.0),\n",
       " (126, 5.0),\n",
       " (85, 5.0),\n",
       " (1075, 5.0),\n",
       " (1198, 5.0),\n",
       " (589, 5.0),\n",
       " (991, 5.0),\n",
       " (1579, 5.0),\n",
       " (95, 5.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get neighbours\n",
    "kNeighbors = getNeighbors(referenceUser,10,trainSet)\n",
    "kNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bb1f76",
   "metadata": {},
   "source": [
    "De esta forma se seleccionan las k primeras películas con mayor puntuación, en este caso se seleccionan las 10 primeras, pero, no deberíamos seleccionar un número variable de k de tal forma que se seleccionen todas aquellas que tengan un rating máximo (5)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf34f074",
   "metadata": {},
   "source": [
    "## Candidate generation and scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244bec4c",
   "metadata": {},
   "source": [
    "Selecionamos las películas que podríamos recomendar en primera instancia. Para ello normalizamos los ratings y multiplicamos por el coeficiente de semejanza entre las películas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e52037ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get similar items to stuff we liked (weighted by rating)\n",
    "candidates = defaultdict(float)\n",
    "for itemID, rating in kNeighbors:\n",
    "    similarityRow = simsMatrix[itemID]\n",
    "    for innerID, score in enumerate(similarityRow):\n",
    "#         print(score)\n",
    "#         print(rating)\n",
    "        candidates[innerID] += score*(rating/5.0)\n",
    "\n",
    "# Sort the candidates by score\n",
    "candidates = sorted(candidates.items(), key=itemgetter(1), reverse=True)\n",
    "#candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8ae3cd",
   "metadata": {},
   "source": [
    "El score corresponde con la medida cosine similarity entre las películas calculada en la matriz de similaridad, mientras que rating corresponde con la valoración del usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e97e79",
   "metadata": {},
   "source": [
    "## Candidate filtering and recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3332c6",
   "metadata": {},
   "source": [
    "Filtramos aquellas recomendaciones con un score pequeño y que ya haya visto el usuario. Para ello utilizamos un set porque únicamente nos interesa saber los items que el reference user ya ha visto, plus es un objeto eficiente para datasets largos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "309421e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterRec(referenceUser,trainSet,k,candidates):\n",
    "    \n",
    "    # Get top N similar users to our reference user\n",
    "    referenceUserInnerID = trainSet.to_inner_uid(referenceUser)\n",
    "    \n",
    "    # Build a set of movies the user has already seen\n",
    "    watched = set(trainSet.ur[referenceUserInnerID])\n",
    "    \n",
    "    # Initialize a list to store the recommendations\n",
    "    recommendations = []\n",
    "\n",
    "    # Get top-rated items from similar users:\n",
    "    pos = 0\n",
    "    for itemID, ratingSum in candidates:\n",
    "        if not itemID in watched:\n",
    "            movieID = trainSet.to_raw_iid(itemID)\n",
    "            recommendation = ml.getMovieName(int(movieID)), ratingSum\n",
    "            recommendations.append(recommendation)\n",
    "            pos += 1\n",
    "            if (pos >= k):\n",
    "                break            \n",
    "\n",
    "    rec_movies = [rec[0] for rec in recommendations]\n",
    "    return rec_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059ff0c",
   "metadata": {},
   "source": [
    "ratingSum represents the total similarity of the reference user to all other users who rated that item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6448b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Star Wars: Episode V - The Empire Strikes Back',\n",
       " 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb',\n",
       " 'Apocalypse Now',\n",
       " 'Chinatown',\n",
       " 'Toy Story',\n",
       " 'Fargo',\n",
       " 'Blade Runner',\n",
       " 'Citizen Kane',\n",
       " 'L.A. Confidential',\n",
       " 'Psycho']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results for the first approach\n",
    "rec_movies = filterRec(referenceUser,trainSet,k,candidates)\n",
    "rec_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83821aac",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8a1a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import evaluationMetrics\n",
    "em = evaluationMetrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ba32282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test and antitest predictions\n",
    "predtest = model.test(testSet)\n",
    "predantitest = model.test(antitest)\n",
    "\n",
    "# Get top N recommended movies for each user based on estimated ratings\n",
    "top_10_SVD = em.getTopN(predantitest,minimumRating = 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95cc373",
   "metadata": {},
   "source": [
    "## Métricas de precisión: RMSE y MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56029491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9172\n",
      "MAE:  0.6978\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "rmse = accuracy.rmse(predtest)\n",
    "\n",
    "# MAE\n",
    "mae = accuracy.mae(predtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd55f78",
   "metadata": {},
   "source": [
    "## Métricas de relevancia: Precision, Recall y NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adb50228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision\n",
    "precisions = em.getPrecision(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Precision\n",
    "mapModel = np.mean(list(precisions.values()))\n",
    "\n",
    "# Recall\n",
    "recalls = em.getRecall(predtest, k=10, threshold=3.5)\n",
    "\n",
    "# Mean Average Recall\n",
    "marModel = np.mean(list(recalls.values()))\n",
    "\n",
    "# Normalized discounted cummulative gain (NDCG)\n",
    "ndcgs, mean_ndcg = em.getNDCG(predtest,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c680ab",
   "metadata": {},
   "source": [
    "## Otras métricas de interés: Coverage, User Coverage y Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3fcb0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage\n",
    "coverage = em.getCoverage(top_10_SVD,trainSet.n_items,trainSet.all_users())\n",
    "\n",
    "# User coverage\n",
    "user_coverage = em.getUserCoverage(top_10_SVD, trainSet.n_users,4)\n",
    "\n",
    "# Novelty\n",
    "novelty = em.getNovelty(top_10_SVD,trainSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501ff50",
   "metadata": {},
   "source": [
    "Por último creamos un dataframe con todas las métricas de evaluación asociadas al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b7d0379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAP</th>\n",
       "      <th>MAR</th>\n",
       "      <th>Mean_NDCG</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>User_Coverage</th>\n",
       "      <th>Novelty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>item-based</td>\n",
       "      <td>0.917171</td>\n",
       "      <td>0.697839</td>\n",
       "      <td>0.743048</td>\n",
       "      <td>0.447952</td>\n",
       "      <td>0.951819</td>\n",
       "      <td>0.020721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5853.927869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Model      RMSE       MAE       MAP       MAR  Mean_NDCG  Coverage  \\\n",
       "0  item-based  0.917171  0.697839  0.743048  0.447952   0.951819  0.020721   \n",
       "\n",
       "   User_Coverage      Novelty  \n",
       "0            1.0  5853.927869  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [\"Model\",\"RMSE\",\"MAE\",\"MAP\",\"MAR\",\"Mean_NDCG\",\"Coverage\",\"User_Coverage\",\"Novelty\"]\n",
    "metrics_data = []\n",
    "\n",
    "# Append the results to the list of dictionaries\n",
    "metrics_data.append({\"Model\": \"item-based\", \"RMSE\": rmse, \"MAE\": mae, \"MAP\": mapModel, \"MAR\": marModel,\n",
    "                     \"Mean_NDCG\": mean_ndcg, \"Coverage\": coverage, \"User_Coverage\": user_coverage,\n",
    "                     \"Novelty\": novelty})\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_data, columns=cols)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46f13ca",
   "metadata": {},
   "source": [
    "* **Coverage**: las recomendaciones son poco variadas, en torno a un 2%.\n",
    "* **User Coverage**: aquí vemos como el modelo encuentra para todos sus usuarios al menos una recomendación por encima de 4 en su predicción\n",
    "* **Novelty**: recomendaciones que han sido pocas veces puntuadas; ranking promedio en torno a la película 5853 más popular (de 8000 posibles) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
